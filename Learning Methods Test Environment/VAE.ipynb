{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder (VAE)\n",
    "A tutorial with code for a VAE as described in [Kingma and Welling, 2013](http://arxiv.org/abs/1312.6114). A talk with more details was given at the [DataLab Brown Bag Seminar](https://home.zhaw.ch/~dueo/bbs/files/vae.pdf).\n",
    "\n",
    "Much of the code was taken, from https://jmetzen.github.io/2015-11-27/vae.html. However, I tried to focus more on the mathematical understanding, not so much on design of the algorithm.\n",
    "\n",
    "### Some theoretical considerations \n",
    "\n",
    "#### Outline\n",
    "Situation: $x$ is from a high-dimensional space and $z$ is from a low-dimensional (latent) space, from which we like to reconstruct $p(x)$. \n",
    "\n",
    "We consider a parameterized model $p_\\theta(x|z)$ (with parameter $\\theta$), to construct x for a given value of $z$. We build this model: \n",
    "\n",
    "* $p_\\theta(x | z)$ with a neural network determening the parameters $\\mu, \\Sigma$ of a Gaussian (or as done here with a Bernoulli-Density). \n",
    "\n",
    "#### Inverting $p_\\theta(x | z)$\n",
    "\n",
    "The inversion is not possible, we therefore approximate $p(z|x)$ by $q_\\phi (z|x)$ again a combination of a NN determening the parameters of a Gaussian\n",
    "\n",
    "* $q_\\phi(z | x)$ with a neural network + Gaussian \n",
    "\n",
    "#### Training\n",
    "\n",
    "We train the network treating it as an autoencoder. \n",
    "\n",
    "#### Lower bound of the Log-Likelihood\n",
    "The likelihood cannot be determined analytically. Therefore, in a first step we derive a lower (variational) bound $L^{v}$ of the log likelihood, for a given image. Technically we assume a discrete latent space. For a continous case simply replace the sum by the appropriate integral over the respective densities. We replace the inaccessible conditional propability $p(z|x)$ with an approximation $q(z|x)$ for which we later use a neural network topped by a Gaussian.\n",
    "\n",
    "\\begin{align}\n",
    "L & = \\log\\left(p(x)\\right) &\\\\\n",
    "  & = \\sum_z q(z|x) \\; \\log\\left(p(x)\\right) &\\text{multiplied with 1 }\\\\\n",
    "  & = \\sum_z q(z|x) \\; \\log\\left(\\frac{p(z,x)}{p(z|x)}\\right) &\\\\\n",
    "  & = \\sum_z q(z|x) \\; \\log\\left(\\frac{p(z,x)}{q(z|x)} \\frac{q(z|x)}{p(z|x)}\\right) &\\\\\n",
    "  & = \\sum_z q(z|x) \\; \\log\\left(\\frac{p(z,x)}{q(z|x)}\\right) + \\sum_z q(z|x) \\; \\log\\left(\\frac{q(z|x)}{p(z|x)}\\right) &\\\\\n",
    "  & = L^{\\tt{v}} + D_{\\tt{KL}} \\left( q(z|x) || p(z|x) \\right) &\\\\\n",
    "  & \\ge L^{\\tt{v}} \\\\\n",
    "\\end{align}\n",
    "\n",
    "The KL-Divergence $D_{\\tt{KL}}$ is always positive, and the smaller the better $q(z|x)$ approximates $p(z|x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewritting  $L^\\tt{v}$\n",
    "We split $L^\\tt{v}$ into two parts.\n",
    "\n",
    "\\begin{align}\n",
    "L^{\\tt{v}} & = \\sum_z q(z|x) \\; \\log\\left(\\frac{p(z,x)}{q(z|x)}\\right)  & \\text{with} \\;\\;p(z,x) = p(x|z) \\,p(z)\\\\\n",
    "  & =  \\sum_z q(z|x) \\; \\log\\left(\\frac{p(x|z) p(z)}{q(z|x)}\\right)  &\\\\\n",
    "  & =  \\sum_z q(z|x) \\; \\log\\left(\\frac{p(z)}{q(z|x)}\\right)  + \\sum_z q(z|x) \\; \\log\\left(p(x|z)\\right) &\\\\\n",
    "  & =  -D_{\\tt{KL}} \\left( q(z|x) || p(z) \\right)  +  \\mathbb{E}_{q(z|x)}\\left( \\log\\left(p(x|z)\\right)\\right) &\\text{putting in } x^{(i)} \\text{ for } x\\\\\n",
    "  & =  -D_{\\tt{KL}} \\left( q(z|x^{(i)}) || p(z) \\right)  +  \\mathbb{E}_{q(z|x^{(i)})}\\left( \\log\\left(p(x^{(i)}|z)\\right)\\right) &\\\\\n",
    "\\end{align}\n",
    "\n",
    "Approximating $\\mathbb{E}_{q(z|x^{(i)})}$ with sampling form the distribution $q(z|x^{(i)})$\n",
    "\n",
    "#### Sampling \n",
    "With $z^{(i,l)}$ $l = 1,2,\\ldots L$ sampled from $z^{(i,l)} \\thicksim q(z|x^{(i)})$\n",
    "\\begin{align}\n",
    "L^{\\tt{v}} & = -D_{\\tt{KL}} \\left( q(z|x^{(i)}) || p(z) \\right)  \n",
    "+  \\mathbb{E}_{q(z|x^{(i)})}\\left( \\log\\left(p(x^{(i)}|z)\\right)\\right) &\\\\\n",
    "L^{\\tt{v}} & \\approx -D_{\\tt{KL}} \\left( q(z|x^{(i)}) || p(z) \\right)  \n",
    "+  \\frac{1}{L} \\sum_{i=1}^L \\log\\left(p(x^{(i)}|z^{(i,l)})\\right) &\\\\\n",
    "\\end{align}\n",
    "\n",
    "#### Calculation of $D_{\\tt{KL}} \\left( q(z|x^{(i)}) || p(z) \\right)$\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\z_outsourced_programs\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow version 1.8.0\n"
     ]
    }
   ],
   "source": [
    "#adhere to https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/mnist/input_data.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import weapon_data as weapons\n",
    "\n",
    "print(\"Tensor Flow version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapon_data = weapons.DataSet(seed=19071991) \n",
    "\n",
    "num_samples = weapon_data.num_examples\n",
    "\n",
    "#training params\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 1\n",
    "epoch_debug_step = 1\n",
    "\n",
    "#network params\n",
    "input_dim = weapon_data.num_features\n",
    "hidden_1_dim = 6\n",
    "hidden_2_dim = 8 #one more to spot errors\n",
    "z_dim = 2 #Dimension of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get variables\n",
    "def create_weight(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "    initial = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initial(shape))\n",
    "\n",
    "def create_bias(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "    initial = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initial(shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the networks\n",
    "#### The encoder network $q_\\phi(z|x)$\n",
    "\n",
    "The decoder network takes the input image and calculates the mean $\\mu =$ `z_mu` and the log variance $\\log(\\sigma^2) =$ `z_ls2` of the Gaussian, thus producing the latent variable z.\n",
    "\n",
    "##### Why $\\log(\\sigma^2)$ instead of the variance $\\sigma^2$ ?\n",
    "The variance $\\sigma^2$ is always > 0 and we don't want to enforce that the network only produces positive numbers. Therefore, we let the network model the parameter $\\log(\\sigma^2) \\in [\\infty, \\infty]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "weight = {\n",
    "    'encoder_h1': create_weight([input_dim, hidden_1_dim]),\n",
    "    'encoder_h2': create_weight([hidden_1_dim, hidden_2_dim]),\n",
    "    'z_mean': create_weight([hidden_1_dim, z_dim]),\n",
    "    'z_ls2': create_weight([hidden_1_dim, z_dim]),\n",
    "    'decoder_h1': create_weight([z_dim, hidden_1_dim]),\n",
    "    'decoder_h2': create_weight([hidden_1_dim, hidden_2_dim]),\n",
    "    'decoder_out': create_weight([hidden_1_dim, input_dim])\n",
    "}\n",
    "bias = {\n",
    "    'encoder_h1': create_bias([hidden_1_dim]),\n",
    "    'encoder_h2': create_bias([hidden_2_dim]),\n",
    "    'z_mean': create_bias([z_dim]),\n",
    "    'z_ls2': create_bias([z_dim]),\n",
    "    'decoder_h1': create_bias([hidden_1_dim]),\n",
    "    'decoder_h2': create_bias([hidden_2_dim]),\n",
    "    'decoder_out': create_bias([input_dim])\n",
    "}\n",
    "\n",
    "# Input\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_dim]) \n",
    "\n",
    "# First hidden layer\n",
    "encoder_h1 = tf.matmul(x, weight['encoder_h1']) + bias['encoder_h1']\n",
    "encoder_h1 = tf.nn.tanh(encoder_h1)\n",
    "\n",
    "# Second hidden layer\n",
    "encoder_h2 = tf.matmul(encoder_h1, weight['encoder_h2']) + bias['encoder_h2']\n",
    "encoder_h2 = tf.nn.tanh(encoder_h2)\n",
    "\n",
    "# Parameters for the Gaussian\n",
    "z_mu = tf.matmul(encoder_h1, weight['z_mean']) + bias['z_mean']\n",
    "z_ls2 = tf.matmul(encoder_h1, weight['z_ls2']) + bias['z_ls2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The decoder network $p_\\theta(x|z)$ a.k.a. generator network\n",
    "\n",
    "Samples from a Gaussian using the given mean and the std. The sampling is done by addding a random number ensuring that backpropagation works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a random number from the normal (gaussian) distribution\n",
    "epsilon = tf.random_normal((batch_size, z_dim), 0, 1, dtype=tf.float32) \n",
    "\n",
    "# sample z from a normal (gaussian) distribution\n",
    "z = z_mu + tf.multiply(tf.sqrt(tf.exp(z_ls2)), epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_h1 = tf.matmul(z, weight['decoder_h1']) + bias['decoder_h1']\n",
    "decoder_h1 = tf.nn.tanh(decoder_h1)\n",
    "\n",
    "decoder_h2 = tf.matmul(decoder_h1, weight['decoder_h2']) + bias['decoder_h2']\n",
    "decoder_h2 = tf.nn.tanh(decoder_h2)\n",
    "\n",
    "x_reconstr = tf.matmul(decoder_h1,  weight['decoder_out']) + bias['decoder_out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the loss function\n",
    "\n",
    "##### The reconstruction error\n",
    "We assume that the data x, is Gaussian distributed with diagnoal covariance matrix $\\Sigma_{ij} = \\delta_{i,j} \\sigma_i^2$. The parameters of that Gaussian are determined by the encoder network. The reconstruction error for the $i-th$ example in the min-batch is given by \n",
    "$$\n",
    "    \\mathbb{E}_{q(z|x^{(i)})}\\left( \\log\\left(p(x^{(i)}|z)\\right)\\right) \n",
    "$$\n",
    "we approximate the expectation with samplinging from the distribution (eaven with $L=1$)\n",
    "$$\n",
    "    \\mathbb{E}_{q(z|x^{(i)})}\\left( \\log\\left(p(x^{(i)}|z)\\right)\\right) \\approx \n",
    "    \\frac{1}{L} \\sum_{i=1}^L \\log\\left(p(x^{(i)}|z^{(i,l)})\\right) \\approx \\log\\left(p(x^{(i)}|z^{(i,l)})\\right)\n",
    "$$\n",
    "\n",
    "For the simple $J-dimensional$ Gaussian, we obtain the following reconstruction error (neglegting a constant term)\n",
    "$$\n",
    "    -\\log\\left(p(x^{(i)}|z^{(i)})\\right) = \\sum_{j=1}^D \\frac{1}{2} \\log(\\sigma_{x_j}^2) + \\frac{(x^{(i)}_j - \\mu_{x_j})^2}{2 \\sigma_{x_j}^2}\n",
    "$$\n",
    "\n",
    "##### The regularisation term\n",
    "\n",
    "$$\n",
    "    -D_{\\tt{KL}} \\left( q(z|x^{(i)}) || p(z) \\right) = \\frac{1}{2} \\sum_{j=1}^{J} \\left(1 + \\log(\\sigma_{z_j}^{(i)^2}) - \\mu_{z_j}^{(i)^2} - \\sigma_{z_j}^{(i)^2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kullbackLeibler(mu, log_sigma):\n",
    "    \"\"\"(Gaussian) Kullback-Leibler divergence KL(q||p), per training example\"\"\"\n",
    "    # (tf.Tensor, tf.Tensor) -> tf.Tensor\n",
    "    with tf.name_scope(\"KL_divergence\"):\n",
    "        # = -0.5 * (1 + log(sigma**2) - mu**2 - sigma**2)\n",
    "        return -0.5 * tf.reduce_sum(1 + 2 * log_sigma - mu**2 -\n",
    "                                    tf.exp(2 * log_sigma), 1)\n",
    "\n",
    "def crossEntropy(obs, actual, offset=1e-7):\n",
    "    \"\"\"Binary cross-entropy, per training example\"\"\"\n",
    "    # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "    with tf.name_scope(\"cross_entropy\"):\n",
    "        # bound by clipping to avoid nan (--> log(0))\n",
    "        obs_ = tf.clip_by_value(obs, offset, 1 - offset)\n",
    "    return -tf.reduce_sum(actual * tf.log(obs_) + (1 - actual) * tf.log(1 - obs_), 1)\n",
    "\n",
    "def l1_loss(obs, actual):\n",
    "    \"\"\"L1 loss (a.k.a. LAD), per training example\"\"\"\n",
    "    # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "    with tf.name_scope(\"l1_loss\"):\n",
    "        return tf.reduce_sum(tf.abs(obs - actual) , 1)\n",
    "\n",
    "def l2_loss(obs, actual):\n",
    "    \"\"\"L2 loss (a.k.a. Euclidean / LSE), per training example\"\"\"\n",
    "    # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "    with tf.name_scope(\"l2_loss\"):\n",
    "        return tf.reduce_sum(tf.square(obs - actual), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#according to the VAE tutorial paper:\n",
    "reconstr_loss = tf.reduce_sum(tf.square(tf.abs(x - x_reconstr)), 1)\n",
    "\n",
    "#reconstr_loss = l2_loss(x_reconstr, x)\n",
    "#reconstr_loss = crossEntropy(x_reconstr, x)\n",
    "\n",
    " \n",
    "latent_loss = kullbackLeibler(z_mu, tf.log(tf.sqrt(tf.exp(z_ls2))))\n",
    "\n",
    "cost = tf.reduce_mean(reconstr_loss + latent_loss)   # average over batch\n",
    "\n",
    "# Use ADAM optimizer\n",
    "optimizer =  tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001, cost=22.862524033\n",
      "Epoch:0002, cost=20.632991446\n",
      "Epoch:0003, cost=19.936219902\n",
      "Epoch:0004, cost=18.298102550\n",
      "Epoch:0005, cost=16.862121286\n",
      "Epoch:0006, cost=16.671377321\n",
      "Epoch:0007, cost=15.516848290\n",
      "Epoch:0008, cost=14.961065238\n",
      "Epoch:0009, cost=13.724146334\n",
      "Epoch:0010, cost=13.430200400\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if False:\n",
    "    while False:\n",
    "        sess = tf.Session()  \n",
    "        sess.run(init)\n",
    "        batch_xs = next_batch(batch_size)\n",
    "        dd = sess.run([cost], feed_dict={x: batch_xs})\n",
    "        print('Test run of cost operation in while loop results in {}'.format(dd))\n",
    "        if not np.isnan(dd) and not np.isinf(dd):\n",
    "            break\n",
    "        else:\n",
    "            sess.close()\n",
    "            \n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(num_samples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs = weapon_data.next_batch(batch_size)\n",
    "            _, d, z_mean_val, z_log_sigma_sq_val = sess.run((optimizer, cost,  z_mu, z_ls2), feed_dict={x: batch_xs})\n",
    "            avg_cost += d / num_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % epoch_debug_step == 0:\n",
    "            save_path = saver.save(sess, \"weapon_data_model/vae.ckpt\") #Saves the weights (not the graph)\n",
    "            #print(\"Model saved in file: {}\".format(save_path))\n",
    "            print(\"Epoch:\"+ '%04d' % (epoch+1) + \", cost=\" + \"{:.9f}\".format(avg_cost))\n",
    "            #print (\"{} {} mean sigma2 {}\".format(z_mean_val.min(), z_mean_val.max(), np.mean(np.exp(z_log_sigma_sq_val))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from weapon_data_model/vae.ckpt\n",
      "[[-0.07708282 -0.3616659   0.37119814 -0.05845876 -0.22336265 -0.76902396\n",
      "   1.31937134 -0.59816232 -0.08116716  0.02373263 -0.61710805 -0.28002455\n",
      "  -0.07024758 -0.13148006 -0.27381253 -0.12270686 -0.28577464 -0.32322997\n",
      "  -0.50421948  1.83110381 -0.36023741 -0.52522573 -0.40663784 -0.2672411 ]]\n",
      "[[-0.01731053 -0.40239686  0.3877413  -0.34072345 -0.03974342 -0.55647266\n",
      "   0.6989297  -0.27593935 -0.30584237  0.04205328  0.05208966 -0.05824691\n",
      "  -0.39548352 -0.41576388 -0.2860552  -0.17311363 -0.05636793  0.00848803\n",
      "   0.53044236  0.38716853 -0.38058317 -0.47656074 -0.3764696  -0.06030756]]\n",
      "damages_first = ['42.0', '43.479550768741035']\n",
      "damages_last = ['23.0', '22.0230941980742']\n",
      "dmg_distances_first = ['21.0', '21.245876827128303']\n",
      "dmg_distances_last = ['60.0', '48.229370357321486']\n",
      "drag = ['0.0024999999441206455', '0.002722180444148224']\n",
      "firemode_Automatic = ['0.0', '0.10271287104741827']\n",
      "firemode_Semi-Automatic = ['1.0', '0.7013242165183013']\n",
      "hiprecoildec = ['5.25', '4.637137530433626']\n",
      "hiprecoilright = ['0.6000000238418579', '0.6072136992841372']\n",
      "hiprecoilup = ['0.8999999761581423', '2.7814098461079846']\n",
      "hordispersion = ['0.0', '0.11558831236986183']\n",
      "initialspeed = ['570.0', '501.8660846655174']\n",
      "magsize = ['21.0', '8.903468092108689']\n",
      "reloadempty = ['3.5', '3.4833065296995436']\n",
      "rof = ['299.0', '287.8281746213014']\n",
      "shotspershell = ['1.0', '1.6617295620274821']\n",
      "type_Shotgun = ['-1.3877787807814457e-17', '0.09707865166092937']\n",
      "type_Pistol = ['2.7755575615628914e-17', '0.415947336830353']\n",
      "type_Rifle = ['1.0', '0.3925956488734472']\n",
      "type_Submachine Gun = ['0.0', '-0.006487423118783309']\n",
      "type_Sniper Rifle = ['0.0', '0.020033595693650236']\n",
      "verdispersion = ['0.0', '0.09862284878129626']\n"
     ]
    }
   ],
   "source": [
    "genDict = {}\n",
    "\n",
    "def addGeneratedWeapon(generatedWeaponTensorDict):\n",
    "    for key, value in generatedWeaponTensorDict.items():\n",
    "        if key not in genDict:\n",
    "            genDict[key] = []\n",
    "        genDict[key].append(value)\n",
    "        \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"weapon_data_model/vae.ckpt\")\n",
    "    \n",
    "    samples = weapon_data.next_batch(batch_size)\n",
    "    reconstruction = sess.run((x_reconstr), feed_dict={x: samples})\n",
    "    \n",
    "    print(samples)\n",
    "    print(reconstruction)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        addGeneratedWeapon(weapon_data.decode_processed_tensor(samples[i]))\n",
    "    for i in range(batch_size):\n",
    "        addGeneratedWeapon(weapon_data.decode_processed_tensor(reconstruction[i]))\n",
    "    \n",
    "weapons.debug_printDict(genDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from weapon_data_model/vae.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "all_z = np.zeros((1,2))\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"weapon_data_model/vae.ckpt\")\n",
    "    total_batch = int(num_samples / batch_size) \n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs = weapon_data.next_batch(batch_size)\n",
    "        x_reconstruct,z_vals,z_mean_val,z_log_sigma_sq_val  = \\\n",
    "        sess.run((x_reconstr,z, z_mu, z_ls2), feed_dict={x: batch_xs})\n",
    "        all_z = np.vstack((all_z, z_mean_val))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x209be267f28>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x209be136f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(all_z[:,0], all_z[:,1])\n",
    "plt.xlim(-0.5,0.5)\n",
    "plt.ylim(-0.5,0.5)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist2d(all_z[:,0], all_z[:,1], (100, 100), cmap=plt.cm.jet)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
