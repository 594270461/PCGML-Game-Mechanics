{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder (VAE)\n",
    "A tutorial with code for a VAE as described in [Kingma and Welling, 2013](http://arxiv.org/abs/1312.6114). A talk with more details was given at the [DataLab Brown Bag Seminar](https://home.zhaw.ch/~dueo/bbs/files/vae.pdf).\n",
    "\n",
    "Much of the code was taken, from https://jmetzen.github.io/2015-11-27/vae.html. However, I tried to focus more on the mathematical understanding, not so much on design of the algorithm.\n",
    "\n",
    "### Some theoretical considerations \n",
    "\n",
    "#### Outline\n",
    "Situation: $x$ is from a high-dimensional space and $z$ is from a low-dimensional (latent) space, from which we like to reconstruct $p(x)$. \n",
    "\n",
    "We consider a parameterized model $p_\\theta(x|z)$ (with parameter $\\theta$), to construct x for a given value of $z$. We build this model: \n",
    "\n",
    "* $p_\\theta(x | z)$ with a neural network determening the parameters $\\mu, \\Sigma$ of a Gaussian (or as done here with a Bernoulli-Density). \n",
    "\n",
    "#### Inverting $p_\\theta(x | z)$\n",
    "\n",
    "The inversion is not possible, we therefore approximate $p(z|x)$ by $q_\\phi (z|x)$ again a combination of a NN determening the parameters of a Gaussian\n",
    "\n",
    "* $q_\\phi(z | x)$ with a neural network + Gaussian \n",
    "\n",
    "#### Training\n",
    "\n",
    "We train the network treating it as an autoencoder. \n",
    "\n",
    "#### Lower bound of the Log-Likelihood\n",
    "The likelihood cannot be determined analytically. Therefore, in a first step we derive a lower (variational) bound $L^{v}$ of the log likelihood, for a given image. Technically we assume a discrete latent space. For a continous case simply replace the sum by the appropriate integral over the respective densities. We replace the inaccessible conditional propability $p(z|x)$ with an approximation $q(z|x)$ for which we later use a neural network topped by a Gaussian.\n",
    "\n",
    "\\begin{align}\n",
    "L & = \\log\\left(p(x)\\right) &\\\\\n",
    "  & = \\sum_z q(z|x) \\; \\log\\left(p(x)\\right) &\\text{multiplied with 1 }\\\\\n",
    "  & = \\sum_z q(z|x) \\; \\log\\left(\\frac{p(z,x)}{p(z|x)}\\right) &\\\\\n",
    "  & = \\sum_z q(z|x) \\; \\log\\left(\\frac{p(z,x)}{q(z|x)} \\frac{q(z|x)}{p(z|x)}\\right) &\\\\\n",
    "  & = \\sum_z q(z|x) \\; \\log\\left(\\frac{p(z,x)}{q(z|x)}\\right) + \\sum_z q(z|x) \\; \\log\\left(\\frac{q(z|x)}{p(z|x)}\\right) &\\\\\n",
    "  & = L^{\\tt{v}} + D_{\\tt{KL}} \\left( q(z|x) || p(z|x) \\right) &\\\\\n",
    "  & \\ge L^{\\tt{v}} \\\\\n",
    "\\end{align}\n",
    "\n",
    "The KL-Divergence $D_{\\tt{KL}}$ is always positive, and the smaller the better $q(z|x)$ approximates $p(z|x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewritting  $L^\\tt{v}$\n",
    "We split $L^\\tt{v}$ into two parts.\n",
    "\n",
    "\\begin{align}\n",
    "L^{\\tt{v}} & = \\sum_z q(z|x) \\; \\log\\left(\\frac{p(z,x)}{q(z|x)}\\right)  & \\text{with} \\;\\;p(z,x) = p(x|z) \\,p(z)\\\\\n",
    "  & =  \\sum_z q(z|x) \\; \\log\\left(\\frac{p(x|z) p(z)}{q(z|x)}\\right)  &\\\\\n",
    "  & =  \\sum_z q(z|x) \\; \\log\\left(\\frac{p(z)}{q(z|x)}\\right)  + \\sum_z q(z|x) \\; \\log\\left(p(x|z)\\right) &\\\\\n",
    "  & =  -D_{\\tt{KL}} \\left( q(z|x) || p(z) \\right)  +  \\mathbb{E}_{q(z|x)}\\left( \\log\\left(p(x|z)\\right)\\right) &\\text{putting in } x^{(i)} \\text{ for } x\\\\\n",
    "  & =  -D_{\\tt{KL}} \\left( q(z|x^{(i)}) || p(z) \\right)  +  \\mathbb{E}_{q(z|x^{(i)})}\\left( \\log\\left(p(x^{(i)}|z)\\right)\\right) &\\\\\n",
    "\\end{align}\n",
    "\n",
    "Approximating $\\mathbb{E}_{q(z|x^{(i)})}$ with sampling form the distribution $q(z|x^{(i)})$\n",
    "\n",
    "#### Sampling \n",
    "With $z^{(i,l)}$ $l = 1,2,\\ldots L$ sampled from $z^{(i,l)} \\thicksim q(z|x^{(i)})$\n",
    "\\begin{align}\n",
    "L^{\\tt{v}} & = -D_{\\tt{KL}} \\left( q(z|x^{(i)}) || p(z) \\right)  \n",
    "+  \\mathbb{E}_{q(z|x^{(i)})}\\left( \\log\\left(p(x^{(i)}|z)\\right)\\right) &\\\\\n",
    "L^{\\tt{v}} & \\approx -D_{\\tt{KL}} \\left( q(z|x^{(i)}) || p(z) \\right)  \n",
    "+  \\frac{1}{L} \\sum_{i=1}^L \\log\\left(p(x^{(i)}|z^{(i,l)})\\right) &\\\\\n",
    "\\end{align}\n",
    "\n",
    "#### Calculation of $D_{\\tt{KL}} \\left( q(z|x^{(i)}) || p(z) \\right)$\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\z_outsourced_programs\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow version 1.8.0\n"
     ]
    }
   ],
   "source": [
    "#adhere to https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/mnist/input_data.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import weapon_data as weapons\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Tensor Flow version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapon_data = weapons.DataSet(seed=19071991) \n",
    "\n",
    "num_samples = weapon_data.num_examples\n",
    "\n",
    "#training params\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "epoch_debug_step = 1\n",
    "\n",
    "#network params\n",
    "input_dim = weapon_data.num_features\n",
    "hidden_1_dim = 14\n",
    "hidden_2_dim = 15 #one more to spot errors\n",
    "z_dim = 2 #Dimension of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get variables\n",
    "def create_weight(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "    initial = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initial(shape))\n",
    "\n",
    "def create_bias(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    #initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "    initial = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initial(shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the networks\n",
    "#### The encoder network $q_\\phi(z|x)$\n",
    "\n",
    "The decoder network takes the input image and calculates the mean $\\mu =$ `z_mu` and the log variance $\\log(\\sigma^2) =$ `z_ls2` of the Gaussian, thus producing the latent variable z.\n",
    "\n",
    "##### Why $\\log(\\sigma^2)$ instead of the variance $\\sigma^2$ ?\n",
    "The variance $\\sigma^2$ is always > 0 and we don't want to enforce that the network only produces positive numbers. Therefore, we let the network model the parameter $\\log(\\sigma^2) \\in [\\infty, \\infty]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "weight = {\n",
    "    'encoder_h1': create_weight([input_dim, hidden_1_dim]),\n",
    "    'encoder_h2': create_weight([hidden_1_dim, hidden_2_dim]),\n",
    "    'z_mean': create_weight([hidden_2_dim, z_dim]),\n",
    "    'z_ls2': create_weight([hidden_2_dim, z_dim]),\n",
    "    'decoder_h1': create_weight([z_dim, hidden_1_dim]),\n",
    "    'decoder_h2': create_weight([hidden_1_dim, hidden_2_dim]),\n",
    "    'decoder_out': create_weight([hidden_2_dim, input_dim])\n",
    "}\n",
    "bias = {\n",
    "    'encoder_h1': create_bias([hidden_1_dim]),\n",
    "    'encoder_h2': create_bias([hidden_2_dim]),\n",
    "    'z_mean': create_bias([z_dim]),\n",
    "    'z_ls2': create_bias([z_dim]),\n",
    "    'decoder_h1': create_bias([hidden_1_dim]),\n",
    "    'decoder_h2': create_bias([hidden_2_dim]),\n",
    "    'decoder_out': create_bias([input_dim])\n",
    "}\n",
    "\n",
    "# Input\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_dim]) \n",
    "\n",
    "# First hidden layer\n",
    "encoder_h1 = tf.matmul(x, weight['encoder_h1']) + bias['encoder_h1']\n",
    "encoder_h1 = tf.nn.tanh(encoder_h1)\n",
    "\n",
    "# Second hidden layer\n",
    "encoder_h2 = tf.matmul(encoder_h1, weight['encoder_h2']) + bias['encoder_h2']\n",
    "encoder_h2 = tf.nn.tanh(encoder_h2)\n",
    "\n",
    "# Parameters for the Gaussian\n",
    "z_mu = tf.matmul(encoder_h2, weight['z_mean']) + bias['z_mean']\n",
    "z_ls2 = tf.matmul(encoder_h2, weight['z_ls2']) + bias['z_ls2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The decoder network $p_\\theta(x|z)$ a.k.a. generator network\n",
    "\n",
    "Samples from a Gaussian using the given mean and the std. The sampling is done by addding a random number ensuring that backpropagation works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a random number from the normal (gaussian) distribution\n",
    "epsilon = tf.random_normal((batch_size, z_dim), 0, 1, dtype=tf.float32) \n",
    "\n",
    "# sample z from a normal (gaussian) distribution\n",
    "z = z_mu + tf.multiply(tf.sqrt(tf.exp(z_ls2)), epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_op(z_input):\n",
    "    decoder_h1 = tf.matmul(z_input, weight['decoder_h1']) + bias['decoder_h1']\n",
    "    decoder_h1 = tf.nn.tanh(decoder_h1)\n",
    "\n",
    "    decoder_h2 = tf.matmul(decoder_h1, weight['decoder_h2']) + bias['decoder_h2']\n",
    "    decoder_h2 = tf.nn.tanh(decoder_h2)\n",
    "    \n",
    "    x_reconstr = tf.matmul(decoder_h2,  weight['decoder_out']) + bias['decoder_out']\n",
    "    #x_reconstr = tf.nn.sigmoid(x_reconstr)\n",
    "    return x_reconstr\n",
    "\n",
    "decoder = decoder_op(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the loss function\n",
    "\n",
    "##### The reconstruction error\n",
    "We assume that the data x, is Gaussian distributed with diagnoal covariance matrix $\\Sigma_{ij} = \\delta_{i,j} \\sigma_i^2$. The parameters of that Gaussian are determined by the encoder network. The reconstruction error for the $i-th$ example in the min-batch is given by \n",
    "$$\n",
    "    \\mathbb{E}_{q(z|x^{(i)})}\\left( \\log\\left(p(x^{(i)}|z)\\right)\\right) \n",
    "$$\n",
    "we approximate the expectation with samplinging from the distribution (eaven with $L=1$)\n",
    "$$\n",
    "    \\mathbb{E}_{q(z|x^{(i)})}\\left( \\log\\left(p(x^{(i)}|z)\\right)\\right) \\approx \n",
    "    \\frac{1}{L} \\sum_{i=1}^L \\log\\left(p(x^{(i)}|z^{(i,l)})\\right) \\approx \\log\\left(p(x^{(i)}|z^{(i,l)})\\right)\n",
    "$$\n",
    "\n",
    "For the simple $J-dimensional$ Gaussian, we obtain the following reconstruction error (neglegting a constant term)\n",
    "$$\n",
    "    -\\log\\left(p(x^{(i)}|z^{(i)})\\right) = \\sum_{j=1}^D \\frac{1}{2} \\log(\\sigma_{x_j}^2) + \\frac{(x^{(i)}_j - \\mu_{x_j})^2}{2 \\sigma_{x_j}^2}\n",
    "$$\n",
    "\n",
    "##### The regularisation term\n",
    "\n",
    "$$\n",
    "    -D_{\\tt{KL}} \\left( q(z|x^{(i)}) || p(z) \\right) = \\frac{1}{2} \\sum_{j=1}^{J} \\left(1 + \\log(\\sigma_{z_j}^{(i)^2}) - \\mu_{z_j}^{(i)^2} - \\sigma_{z_j}^{(i)^2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kullbackLeibler(mu, log_sigma):\n",
    "    \"\"\"(Gaussian) Kullback-Leibler divergence KL(q||p), per training example\"\"\"\n",
    "    # (tf.Tensor, tf.Tensor) -> tf.Tensor\n",
    "    with tf.name_scope(\"KL_divergence\"):\n",
    "        # = -0.5 * (1 + log(sigma**2) - mu**2 - sigma**2)\n",
    "        return -0.5 * tf.reduce_sum(1 + 2 * log_sigma - mu**2 -\n",
    "                                    tf.exp(2 * log_sigma), 1)\n",
    "\n",
    "def crossEntropy(obs, actual, offset=1e-7):\n",
    "    \"\"\"Binary cross-entropy, per training example\"\"\"\n",
    "    # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "    with tf.name_scope(\"cross_entropy\"):\n",
    "        # bound by clipping to avoid nan (--> log(0))\n",
    "        obs_ = tf.clip_by_value(obs, offset, 1 - offset)\n",
    "    return -tf.reduce_sum(actual * tf.log(obs_) + (1 - actual) * tf.log(1 - obs_), 1)\n",
    "\n",
    "def l1_loss(obs, actual):\n",
    "    \"\"\"L1 loss (a.k.a. LAD), per training example\"\"\"\n",
    "    # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "    with tf.name_scope(\"l1_loss\"):\n",
    "        return tf.reduce_sum(tf.abs(obs - actual) , 1)\n",
    "\n",
    "def l2_loss(obs, actual):\n",
    "    \"\"\"L2 loss (a.k.a. Euclidean / LSE), per training example\"\"\"\n",
    "    # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "    with tf.name_scope(\"l2_loss\"):\n",
    "        return tf.reduce_sum(tf.square(obs - actual), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#according to the VAE tutorial paper:\n",
    "reconstr_loss = tf.reduce_sum(tf.square(tf.abs(x - decoder)), 1)\n",
    "\n",
    "#reconstr_loss = l2_loss(decoder, x)\n",
    "#reconstr_loss = crossEntropy(decoder, x)\n",
    "\n",
    " \n",
    "latent_loss = kullbackLeibler(z_mu, tf.log(tf.sqrt(tf.exp(z_ls2))))\n",
    "\n",
    "cost = tf.reduce_mean(reconstr_loss + latent_loss)   # average over batch\n",
    "\n",
    "# Use ADAM optimizer\n",
    "#optimizer =  tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "optimizer =  tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001, cost=23.101199511\n",
      "Epoch:0002, cost=23.153032870\n",
      "Epoch:0003, cost=22.839189220\n",
      "Epoch:0004, cost=22.284894892\n",
      "Epoch:0005, cost=22.889265370\n",
      "Epoch:0006, cost=19.916324229\n",
      "Epoch:0007, cost=20.131305488\n",
      "Epoch:0008, cost=19.501154938\n",
      "Epoch:0009, cost=17.799623721\n",
      "Epoch:0010, cost=18.199885729\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if False:\n",
    "    while False:\n",
    "        sess = tf.Session()  \n",
    "        sess.run(init)\n",
    "        batch_xs = next_batch(batch_size)\n",
    "        dd = sess.run([cost], feed_dict={x: batch_xs})\n",
    "        print('Test run of cost operation in while loop results in {}'.format(dd))\n",
    "        if not np.isnan(dd) and not np.isinf(dd):\n",
    "            break\n",
    "        else:\n",
    "            sess.close()\n",
    "            \n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(num_samples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs = weapon_data.next_batch(batch_size)\n",
    "            _, d, z_mean_val, z_log_sigma_sq_val = sess.run((optimizer, cost,  z_mu, z_ls2), feed_dict={x: batch_xs})\n",
    "            avg_cost += d / num_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % epoch_debug_step == 0:\n",
    "            save_path = saver.save(sess, \"weapon_data_model/vae.ckpt\") #Saves the weights (not the graph)\n",
    "            #print(\"Model saved in file: {}\".format(save_path))\n",
    "            print(\"Epoch:\"+ '%04d' % (epoch+1) + \", cost=\" + \"{:.9f}\".format(avg_cost))\n",
    "            #print (\"{} {} mean sigma2 {}\".format(z_mean_val.min(), z_mean_val.max(), np.mean(np.exp(z_log_sigma_sq_val))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from weapon_data_model/vae.ckpt\n",
      "[[-1.26885166e+00 -1.06003774e+00 -9.97778024e-02 -9.93695305e-01\n",
      "   3.49562516e+00 -7.69023959e-01 -7.57936729e-01  1.67178701e+00\n",
      "  -9.06016537e-01  1.03961711e+00  2.97535578e+00  3.17360952e+00\n",
      "  -1.20156256e+00 -4.83999063e-01 -2.46162033e-03 -1.11984876e+00\n",
      "   3.52767706e+00  3.09377255e+00 -5.04219484e-01 -5.46118681e-01\n",
      "  -3.60237411e-01 -5.25225731e-01 -4.06637837e-01  3.50957490e+00]\n",
      " [-1.40620805e+00 -1.13091727e+00 -9.97778024e-02 -9.93695305e-01\n",
      "   3.49562516e+00 -7.69023959e-01  1.31937134e+00 -5.98162323e-01\n",
      "  -3.56116951e-01 -2.30238568e-01  1.19690834e+00  2.78987253e+00\n",
      "  -1.20156256e+00 -5.07500330e-01 -1.88251314e-01 -7.36332643e-01\n",
      "   3.52767706e+00  3.09377255e+00 -5.04219484e-01 -5.46118681e-01\n",
      "  -3.60237411e-01 -5.25225731e-01 -4.06637837e-01  3.08992881e+00]\n",
      " [-5.61870144e-01 -6.95216633e-01 -2.14830501e-01 -7.11685557e-01\n",
      "  -2.23362650e-01 -7.69023959e-01  1.31937134e+00 -5.98162323e-01\n",
      "  -1.72817088e-01 -2.30238568e-01 -4.03694350e-01 -2.80024546e-01\n",
      "  -1.12041338e+00 -4.13495263e-01 -1.33721512e+00 -1.22706864e-01\n",
      "  -2.85774635e-01 -3.23229968e-01  1.98326330e+00 -5.46118681e-01\n",
      "  -3.60237411e-01 -5.25225731e-01 -4.06637837e-01 -2.67241097e-01]\n",
      " [-6.42668031e-01 -4.45053585e-01 -3.01624637e-01 -6.57969367e-01\n",
      "  -2.23362650e-01  1.30034960e+00 -7.57936729e-01 -5.98162323e-01\n",
      "   1.93782636e-01 -7.88975064e-01 -8.19851047e-01 -2.80024546e-01\n",
      "   1.36179670e+00  1.72512002e+00  4.22899344e-01  7.84195942e-01\n",
      "  -2.85774635e-01 -3.23229968e-01 -5.04219484e-01 -5.46118681e-01\n",
      "  -3.60237411e-01 -5.25225731e-01  2.45919073e+00 -2.67241097e-01]\n",
      " [ 1.45807703e+00  2.01488306e+00 -1.04172970e+00  1.56021986e+00\n",
      "  -2.23362650e-01 -7.69023959e-01 -7.57936729e-01  1.67178701e+00\n",
      "  -3.56116951e-01  1.03961711e+00  8.41218857e-01 -2.80024546e-01\n",
      "   6.45774563e-01 -4.36996530e-01  5.30462148e-01 -1.21911175e+00\n",
      "  -2.85774635e-01 -3.23229968e-01 -5.04219484e-01 -5.46118681e-01\n",
      "  -3.60237411e-01  1.90394328e+00 -4.06637837e-01 -2.67241097e-01]\n",
      " [-7.70828216e-02 -3.61665902e-01  3.71198144e-01 -5.84587639e-02\n",
      "  -2.23362650e-01  1.30034960e+00 -7.57936729e-01 -5.98162323e-01\n",
      "  -9.06016537e-01  2.37326288e-02 -6.81132141e-01 -2.80024546e-01\n",
      "  -7.02475776e-02 -1.31480060e-01 -2.73812532e-01 -1.22706864e-01\n",
      "  -2.85774635e-01 -3.23229968e-01 -5.04219484e-01  1.83110381e+00\n",
      "  -3.60237411e-01 -5.25225731e-01 -4.06637837e-01 -2.67241097e-01]\n",
      " [-7.70828216e-02 -6.98090127e-02  2.38966649e+00  3.73188870e-01\n",
      "  -2.23362650e-01 -7.69023959e-01  1.31937134e+00 -5.98162323e-01\n",
      "  -9.06016537e-01 -1.11913753e+00 -6.34892509e-01 -2.80024546e-01\n",
      "   3.59365707e-01 -5.07500330e-01 -4.69356326e-01  1.48010391e-01\n",
      "  -2.85774635e-01 -3.23229968e-01 -5.04219484e-01  1.83110381e+00\n",
      "  -3.60237411e-01 -5.25225731e-01 -4.06637837e-01 -2.67241097e-01]\n",
      " [ 3.67305557e-01 -6.95216633e-01 -6.38036027e-01 -5.67803013e-01\n",
      "  -2.23362650e-01 -7.69023959e-01  1.31937134e+00 -5.98162323e-01\n",
      "  -1.72817088e-01  5.31674870e-01  8.41218857e-01 -2.80024546e-01\n",
      "  -1.69323110e+00 -4.83999063e-01 -7.50510297e-01 -5.73902290e-01\n",
      "  -2.85774635e-01 -3.23229968e-01  1.98326330e+00 -5.46118681e-01\n",
      "  -3.60237411e-01 -5.25225731e-01 -4.06637837e-01 -2.67241097e-01]\n",
      " [-1.46276659e+00 -1.16010297e+00 -2.34342359e-01 -1.04165615e+00\n",
      "   3.49562516e+00 -7.69023959e-01  1.31937134e+00 -5.98162323e-01\n",
      "  -3.56116951e-01 -2.81032822e-01  6.27805198e-01  2.02240975e+00\n",
      "  -1.20156256e+00 -5.07500330e-01  2.02885233e-01 -3.12208943e-01\n",
      "   3.52767706e+00  3.09377255e+00 -5.04219484e-01 -5.46118681e-01\n",
      "  -3.60237411e-01 -5.25225731e-01 -4.06637837e-01  2.25064891e+00]\n",
      " [-1.36984902e+00 -1.11215505e+00 -2.34342359e-01 -1.04165615e+00\n",
      "   3.49562516e+00  1.30034960e+00 -7.57936729e-01 -5.98162323e-01\n",
      "  -3.56116951e-01  7.85645915e-01  1.62373566e+00  3.17360952e+00\n",
      "  -1.20156256e+00 -5.07500330e-01 -3.69152155e-01 -8.49131500e-01\n",
      "   3.52767706e+00  3.09377255e+00 -5.04219484e-01 -5.46118681e-01\n",
      "  -3.60237411e-01 -5.25225731e-01 -4.06637837e-01  3.50957490e+00]]\n",
      "[[-7.84502178e-02 -6.57679439e-02  3.39488909e-02 -4.88213003e-02\n",
      "  -2.36401670e-02 -2.47323290e-02  7.52146840e-02 -6.39476329e-02\n",
      "  -2.99011581e-02 -6.35467023e-02 -5.12394756e-02 -7.92186894e-03\n",
      "  -2.08448693e-02 -5.00710681e-02 -3.41498666e-02  1.38146430e-02\n",
      "  -3.03839985e-02  1.26226083e-03  5.46041690e-02  2.09057070e-02\n",
      "  -3.07690836e-02 -7.87268281e-02  1.44251222e-02 -2.82222405e-02]\n",
      " [ 1.24697745e-01  1.31750837e-01 -1.67539977e-02  1.46051452e-01\n",
      "   1.04998499e-02 -1.81980237e-01  4.78743277e-02  1.42584294e-01\n",
      "  -1.44754499e-01  1.09041095e-01  1.47114187e-01  1.97403207e-02\n",
      "   2.54874304e-03 -1.60477236e-01 -9.58859622e-02 -1.93756133e-01\n",
      "  -4.30952199e-03  4.66339365e-02  3.71252298e-02 -4.15575691e-04\n",
      "  -1.20172001e-01  1.10220447e-01 -8.09504986e-02  6.39521424e-03]\n",
      " [ 4.62695435e-02  5.19564077e-02  2.69369595e-03  6.98694289e-02\n",
      "   1.57992281e-02 -1.27426803e-01  6.92742541e-02  6.06729686e-02\n",
      "  -7.78319985e-02  4.73984703e-02  9.56124887e-02  1.73576921e-02\n",
      "  -2.45909393e-03 -1.22996308e-01 -7.89044872e-02 -1.25336543e-01\n",
      "  -1.17169488e-02  4.85291146e-02  5.51239364e-02  2.25631353e-02\n",
      "  -8.07661563e-02  2.49013454e-02 -4.79646064e-02  6.90622907e-03]\n",
      " [-4.87616301e-01 -4.83212233e-01  1.31893739e-01 -4.49556500e-01\n",
      "  -5.39580695e-02  3.03169519e-01  1.38458759e-01 -4.89950716e-01\n",
      "   2.81994998e-01 -4.06457484e-01 -4.14503992e-01 -6.08000122e-02\n",
      "  -4.78019193e-02  1.95482045e-01  9.02263522e-02  4.36088502e-01\n",
      "  -7.88667351e-02 -5.25373742e-02  1.01779595e-01  9.58798230e-02\n",
      "   1.91111565e-01 -4.87189531e-01  1.96957409e-01 -6.15552589e-02]\n",
      " [ 1.03061688e+00  1.02165186e+00 -2.49831870e-01  1.00857890e+00\n",
      "   7.93690607e-02 -8.31456661e-01 -1.35202914e-01  1.05685687e+00\n",
      "  -7.24346638e-01  8.53072345e-01  8.91871095e-01  8.68499726e-02\n",
      "   9.58533585e-02 -5.85843801e-01 -3.17158848e-01 -1.03614187e+00\n",
      "   9.76061150e-02  1.51880920e-01 -1.07013002e-01 -1.73231125e-01\n",
      "  -5.21505177e-01  1.00428510e+00 -4.87673998e-01  1.00683033e-01]\n",
      " [ 1.51519924e-02  2.76475102e-02  1.09306015e-02  4.15300280e-02\n",
      "  -1.92939602e-02 -9.40394104e-02  5.62468991e-02  3.24875340e-02\n",
      "  -9.75961387e-02  1.29372552e-02  2.50511803e-02  6.99497759e-05\n",
      "  -1.28283277e-02 -9.85357612e-02 -5.86458556e-02 -7.53564686e-02\n",
      "  -1.99872274e-02  1.01592503e-02  3.98239195e-02  1.92265585e-03\n",
      "  -7.58832991e-02  1.60729140e-02 -2.69472003e-02 -2.11402923e-02]\n",
      " [ 2.85513163e-01  2.92787850e-01 -5.67602217e-02  2.99964070e-01\n",
      "  -6.11120835e-04 -2.90327966e-01  1.36809004e-03  3.08369160e-01\n",
      "  -2.77126849e-01  2.33841985e-01  2.49143124e-01  2.16073878e-02\n",
      "   1.44599080e-02 -2.30906740e-01 -1.27774388e-01 -3.29353422e-01\n",
      "   1.02323256e-02  4.13484424e-02 -2.72950716e-03 -4.83266190e-02\n",
      "  -1.97156161e-01  2.85104901e-01 -1.48623317e-01  5.72340144e-03]\n",
      " [ 4.69333589e-01  4.69307005e-01 -1.03923485e-01  4.74902332e-01\n",
      "   3.22439186e-02 -4.28302079e-01 -2.49300338e-02  4.93267566e-01\n",
      "  -3.72073174e-01  3.89631599e-01  4.27436888e-01  4.44007665e-02\n",
      "   3.80658656e-02 -3.24103862e-01 -1.81116894e-01 -5.12336671e-01\n",
      "   3.39222662e-02  8.33208486e-02 -1.96417607e-02 -6.66883811e-02\n",
      "  -2.71655738e-01  4.54022646e-01 -2.35543400e-01  3.96756604e-02]\n",
      " [-4.59714651e-01 -4.44785535e-01  1.25132591e-01 -4.14876252e-01\n",
      "  -7.71493614e-02  2.83311725e-01  1.22816682e-01 -4.54161584e-01\n",
      "   2.21550435e-01 -3.87397170e-01 -4.15705740e-01 -6.34062290e-02\n",
      "  -5.22919893e-02  1.74475193e-01  8.48845392e-02  4.14812177e-01\n",
      "  -7.68446997e-02 -7.37853274e-02  8.94680321e-02  7.14261457e-02\n",
      "   1.62542820e-01 -4.42690253e-01  1.90894827e-01 -7.75409117e-02]\n",
      " [-4.39573228e-01 -4.26973760e-01  1.20504379e-01 -3.97417396e-01\n",
      "  -6.72235042e-02  2.65054852e-01  1.24299437e-01 -4.35146213e-01\n",
      "   2.17440680e-01 -3.68771970e-01 -3.88444126e-01 -5.80249652e-02\n",
      "  -4.96151075e-02  1.62081882e-01  7.70116001e-02  3.90034318e-01\n",
      "  -7.40242079e-02 -6.26813620e-02  9.06477422e-02  7.40540475e-02\n",
      "   1.54358447e-01 -4.28085506e-01  1.79688901e-01 -7.02285171e-02]]\n",
      "damages_first = ['12.499999999999996', '9.100000381469727', '30.0', '28.0', '80.0', '42.0', '42.0', '53.0', '7.699999809265137', '10.0', '41.966152674405734', '46.99469908862907', '45.05335620933448', '31.83801448909208', '69.41902643922565', '44.2830996555724', '50.97538283094314', '55.525512372582845', '32.52866743762022', '33.02723054304752']\n",
      "damages_last = ['6.2499999999999964', '4.550000190734863', '15.0', '21.0', '80.0', '23.0', '30.0', '15.0', '3.8499999046325684', '5.0', '30.09692243969599', '34.83428350746008', '32.9204653837623', '20.084789349831556', '56.1779879501757', '32.337432092476', '38.696652808999914', '42.930351353957526', '21.006428997322473', '21.43363298300094']\n",
      "dmg_distances_first = ['14.0', '14.0', '12.289999961853027', '11.0', '0.0', '21.0', '51.0', '6.0', '12.0', '12.0', '15.98754704817037', '15.23396245000286', '15.523008750834718', '17.443277308509423', '11.76978318812768', '15.64543185823274', '14.639359752447522', '13.938383740884692', '17.342788015322682', '17.274000046345236']\n",
      "dmg_distances_last = ['21.0', '21.0', '32.7599983215332', '35.0', '127.5', '60.0', '78.0', '38.7599983215332', '18.999999999999993', '18.999999999999993', '60.40188879031923', '68.52821511473945', '65.35137294147712', '43.690958350791306', '104.4961963517726', '64.16960064501554', '74.94647602449426', '82.24152054089708', '45.13714825665251', '45.865194433622236']\n",
      "drag = ['0.007000000216066837', '0.007000000216066837', '0.0024999999441206455', '0.0024999999441206455', '0.0024999999441206455', '0.0024999999441206455', '0.0024999999441206455', '0.0024999999441206455', '0.007000000216066837', '0.007000000216066837', '0.002741665492865146', '0.0027829751430237686', '0.002789387426289105', '0.0027049806267511914', '0.0028663073514906645', '0.002746924432319875', '0.0027695307936495845', '0.0028092856124819366', '0.00267691900757107', '0.002688929361557979']\n",
      "firemode_Automatic = ['0.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '0.0', '1.0', '0.3596700197446762', '0.2836818505336163', '0.3100441445371913', '0.5181246620737918', '-0.03016985593924565', '0.3261782023832364', '0.23132410767750533', '0.1646497692500931', '0.5085286208330442', '0.49970620557417994']\n",
      "firemode_Semi-Automatic = ['0.0', '1.0', '1.0', '0.0', '0.0', '0.0', '1.0', '1.0', '1.0', '0.0', '0.40107263059045467', '0.38791119506265254', '0.39821295371031945', '0.4315178377489946', '0.29977923009497665', '0.3919416859813276', '0.36552345280527254', '0.3528637398660016', '0.42398786328741234', '0.42470165002216137']\n",
      "hiprecoildec = ['3.0', '4.5', '5.0', '6.0', '4.5', '3.0', '3.0', '5.0', '4.5', '4.5', '5.389841892649081', '5.076548309775739', '5.2590975488460945', '6.240623101075756', '3.495553835478378', '5.205185505454491', '4.715466888551651', '4.456475082202028', '6.0757441892627835', '6.064533719409488']\n",
      "hiprecoilright = ['1.0', '0.5', '0.5', '0.2800000011920929', '1.0', '0.6000000238418579', '0.15000000596046448', '0.800000011920929', '0.47999998927116394', '0.8999999761581421', '0.5656341772010728', '0.6335898511597133', '0.6093183432086542', '0.43061458912132977', '0.9265488316782091', '0.5957493937217685', '0.6827296442519936', '0.7440711085824657', '0.43811950247922105', '0.44545309168038966']\n",
      "hiprecoilup = ['11.0', '6.0', '1.5', '0.33000001311302185', '5.0', '0.7200000286102295', '0.8500000238418579', '5.0', '4.400000095367432', '7.199999809265137', '2.490906076632551', '3.048565692371308', '2.903771706158672', '1.4696093319734838', '5.142405776986988', '2.7053927525076116', '3.335414023987096', '3.8366764191615133', '1.4662306860219083', '1.5428751068857025']\n",
      "hordispersion = ['1.7999999523162842', '1.600000023841858', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.2000060081481934', '1.7999999523162842', '0.1418172268365103', '0.15623448678124346', '0.15499268428613322', '0.11425766102663089', '0.19121137425843637', '0.14598248378593792', '0.15720758369003204', '0.1690872674495176', '0.11289932657165619', '0.11570398809096356']\n",
      "initialspeed = ['333.0', '333.0', '350.0', '870.0', '720.0', '570.0', '660.0', '230.0', '333.0', '333.0', '580.3494093535576', '585.2501542528116', '584.2010588372186', '574.702157312514', '604.7966061385553', '582.0288004950709', '587.7454328819178', '592.6906621470033', '573.7615292668586', '574.3223111962192']\n",
      "magsize = ['6.0', '5.0', '9.0', '100.0', '8.0', '21.0', '5.0', '6.0', '5.0', '5.0', '24.46402570096055', '19.766144156206344', '21.360991287029155', '34.91253109876268', '1.666414965860632', '22.401809504625128', '16.769305544391386', '12.8036843369211', '34.01867067311251', '33.49132417957844']\n",
      "reloadempty = ['3.869999885559082', '3.616666793823242', '2.049999952316284', '4.449999809265137', '4.5966668128967285', '3.5', '3.2333667278289795', '2.8499999046325684', '4.150000095367432', '3.369999885559082', '3.8267914533566114', '3.7426113480113923', '3.765766397629182', '3.9963843484045793', '3.440895234829423', '3.7933900061420345', '3.699129962041335', '3.626394915418237', '3.9891005321326314', '3.978365404875868']\n",
      "rof = ['78.00000000000003', '163.0', '299.0', '500.0', '56.0', '299.0', '359.0', '199.0', '257.0', '138.0', '329.25773297514985', '283.2531051696103', '298.4171752533658', '422.8477463435491', '96.5522454525491', '309.49443164881495', '253.20020994143914', '212.64500061581748', '418.1322009794151', '412.6405984433168']\n",
      "shotspershell = ['12.0', '12.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '12.0', '12.0', '1.7366808949908095', '1.8118933967270263', '1.790526482504815', '1.5968311878245474', '2.105871686775204', '1.766670650132605', '1.8538397321994962', '1.9221739782828957', '1.6026638012731502', '1.6107995827675259']\n",
      "type_Shotgun = ['1.0', '1.0', '-1.3877787807814457e-17', '-1.3877787807814457e-17', '-1.3877787807814457e-17', '-1.3877787807814457e-17', '-1.3877787807814457e-17', '-1.3877787807814457e-17', '1.0', '1.0', '0.09496400047838843', '0.10824221009044363', '0.10879684184778785', '0.07921931348867249', '0.1390431776124782', '0.09756774146996668', '0.10669538827592687', '0.11897878755108655', '0.07300101160361454', '0.07625063325161528']\n",
      "type_Pistol = ['2.7755575615628914e-17', '2.7755575615628914e-17', '1.0', '2.7755575615628914e-17', '2.7755575615628914e-17', '2.7755575615628914e-17', '2.7755575615628914e-17', '1.0', '2.7755575615628914e-17', '2.7755575615628914e-17', '0.22465427930893372', '0.21762752148415923', '0.22486323247479015', '0.2436194059262411', '0.15968210270229152', '0.21871242937256818', '0.20160540579832129', '0.1948064628452558', '0.23866999966128138', '0.23914425823149688']\n",
      "type_Rifle = ['2.7755575615628914e-17', '2.7755575615628914e-17', '2.7755575615628914e-17', '2.7755575615628914e-17', '2.7755575615628914e-17', '1.0', '1.0', '2.7755575615628914e-17', '2.7755575615628914e-17', '2.7755575615628914e-17', '0.2385239032140719', '0.2295549140818676', '0.23922111528548465', '0.27006243866759194', '0.15685850070266755', '0.23053851218687527', '0.20940070328308377', '0.201676663061769', '0.2597757796405294', '0.26088123011413966']\n",
      "type_Submachine Gun = ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.10505387209646956', '0.07654696595171886', '0.08911186602398957', '0.17580246703712127', '-0.05142164463323608', '0.09066880796152321', '0.05199988999035424', '0.028245044954333665', '0.16669307169555486', '0.16408341230663714']\n",
      "type_Sniper Rifle = ['0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18380726161400102', '0.26158994147945724', '0.226467188993807', '0.015658111884690407', '0.6296436450423302', '0.22283284682200044', '0.33358347212585165', '0.4031207273773835', '0.03397683648711014', '0.03998907657738532']\n",
      "verdispersion = ['1.7999999523162842', '1.600000023841858', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.2000060081481934', '1.7999999523162842', '0.11391445363381114', '0.1304128525446403', '0.130656398080948', '0.09802820668459905', '0.17534966449507888', '0.11728965286993447', '0.1300926719990124', '0.1462740439952374', '0.09040957386597362', '0.09389460201983307']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent mean = -0.002970, latent variance = 0.700636 \n"
     ]
    }
   ],
   "source": [
    "def print_decoded_tensors_as_dict(weapon_data, array_of_tensors):\n",
    "    genDict = {}\n",
    "    \n",
    "    for tensor in array_of_tensors:\n",
    "        decoded = weapon_data.decode_processed_tensor(tensor)\n",
    "        \n",
    "        for key, value in decoded.items():\n",
    "            if key not in genDict:\n",
    "                genDict[key] = []\n",
    "            genDict[key].append(value)\n",
    "    \n",
    "    for key, value in genDict.items():\n",
    "            print(key, \"=\", value)\n",
    "        \n",
    "        \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"weapon_data_model/vae.ckpt\")\n",
    "    \n",
    "    samples = weapon_data.next_batch(batch_size)\n",
    "    reconstruction = sess.run(decoder, feed_dict={x: samples})\n",
    "    \n",
    "    print(samples)\n",
    "    print(reconstruction)\n",
    "    \n",
    "    print_decoded_tensors_as_dict(weapon_data, np.concatenate((samples, reconstruction), axis=0))\n",
    "    \n",
    "    mean, variance = sess.run((tf.reduce_mean(z_mu), tf.reduce_mean(tf.sqrt(tf.exp(z_ls2)))), feed_dict={x: samples})\n",
    "    print(\"latent mean = %f, latent variance = %f \"%(mean, variance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with tf.Session() as sess:\\n    \\n    saver.restore(sess, \"weapon_data_model/vae.ckpt\")\\n    samples = weapon_data.next_batch(batch_size)\\n\\n    z_vals,z_mean_val,z_log_sigma_sq_val  = sess.run((z, z_mu, z_ls2), feed_dict={x: samples})\\n\\n       \\n    plt.figure(figsize=(8, 12))\\n    for i in range(batch_size):\\n        #plt.colorbar()\\n        plt.subplot(5, 3, 1*i+1)\\n        plt.scatter(z_vals[:,0],z_vals[:,1], c=\\'gray\\', alpha=0.5)\\n        plt.scatter(z_mean_val[i,0],z_mean_val[i,1], c=\\'green\\', s=64, alpha=0.5)\\n        plt.scatter(z_vals[i,0],z_vals[i,1], c=\\'blue\\', s=16, alpha=0.5)\\n\\n        plt.xlim((-3,3))\\n        plt.ylim((-3,3))\\n        plt.title(\"Latent Space\")\\n        \\n                \\n        \\n\\n    plt.tight_layout()\\n    \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess, \"weapon_data_model/vae.ckpt\")\n",
    "    samples = weapon_data.next_batch(batch_size)\n",
    "\n",
    "    z_vals,z_mean_val,z_log_sigma_sq_val  = sess.run((z, z_mu, z_ls2), feed_dict={x: samples})\n",
    "\n",
    "       \n",
    "    plt.figure(figsize=(8, 12))\n",
    "    for i in range(batch_size):\n",
    "        #plt.colorbar()\n",
    "        plt.subplot(5, 3, 1*i+1)\n",
    "        plt.scatter(z_vals[:,0],z_vals[:,1], c='gray', alpha=0.5)\n",
    "        plt.scatter(z_mean_val[i,0],z_mean_val[i,1], c='green', s=64, alpha=0.5)\n",
    "        plt.scatter(z_vals[i,0],z_vals[i,1], c='blue', s=16, alpha=0.5)\n",
    "\n",
    "        plt.xlim((-3,3))\n",
    "        plt.ylim((-3,3))\n",
    "        plt.title(\"Latent Space\")\n",
    "        \n",
    "                \n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from weapon_data_model/vae.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "all_z = np.zeros((1,z_dim))\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"weapon_data_model/vae.ckpt\")\n",
    "    total_batch = int(num_samples / batch_size) \n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs = weapon_data.next_batch(batch_size)\n",
    "        x_reconstruct,z_vals,z_mean_val,z_log_sigma_sq_val  = \\\n",
    "        sess.run((decoder,z, z_mu, z_ls2), feed_dict={x: batch_xs})\n",
    "        all_z = np.vstack((all_z, z_mean_val))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x18ebebef9e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18ebda7a198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(all_z[:,0], all_z[:,1])\n",
    "plt.xlim(-0.5,0.5)\n",
    "plt.ylim(-0.5,0.5)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist2d(all_z[:,0], all_z[:,1], (50, 50), cmap=plt.cm.jet)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "damages_first = ['48.29551521768009', '42.18603815165434', '47.46281729285136', '44.25278920029045']\n",
      "damages_last = ['36.132469647343896', '32.70516719530477', '33.64063408937731', '35.49243171020498']\n",
      "dmg_distances_first = ['15.225219886146531', '18.353926909124645', '18.01292334405192', '16.482774292126916']\n",
      "dmg_distances_last = ['62.04263638612591', '67.3831100250691', '68.0045510915293', '62.95914536335892']\n",
      "drag = ['0.0028970229754082576', '0.0027851430227998158', '0.002649860078314396', '0.002937896760639021']\n",
      "firemode_Automatic = ['0.4045583467153074', '0.3919891459588974', '0.4300927998554176', '0.40011999204064175']\n",
      "firemode_Semi-Automatic = ['0.38064463327099374', '0.440666582910674', '0.47962308679163607', '0.3589528971465606']\n",
      "hiprecoildec = ['5.558184483620075', '5.925943182791487', '5.853946538413455', '5.7240846297644286']\n",
      "hiprecoilright = ['0.6643541192738012', '0.5831004080183583', '0.5817741536910277', '0.6440119513926054']\n",
      "hiprecoilup = ['2.9103469907295065', '2.8680222528423283', '2.7323107236737187', '3.224117702827025']\n",
      "hordispersion = ['0.28465515294832755', '0.13139705447087738', '0.11272763225467636', '0.2650667554911635']\n",
      "initialspeed = ['617.6314285050368', '602.7558584440051', '638.6807177425986', '591.0408330794484']\n",
      "magsize = ['30.98692686322481', '30.993979170934352', '27.68098096002742', '30.136820546089673']\n",
      "reloadempty = ['3.900069210662162', '4.182129902467748', '4.248897402169828', '3.954363355578689']\n",
      "rof = ['332.3147494047176', '354.0167851038534', '372.452459430717', '342.1073901571243']\n",
      "shotspershell = ['1.9397132325417952', '2.2391116356263354', '2.203210694505444', '2.0176181651680283']\n",
      "type_Shotgun = ['0.10581471917713964', '0.13549880580545087', '0.14447128680761218', '0.10045116964055865']\n",
      "type_Pistol = ['0.27822133972374374', '0.22583500157798803', '0.21733014915807117', '0.2755727305999966']\n",
      "type_Rifle = ['0.29224199167050624', '0.23281206016464417', '0.2873212325124734', '0.27311560580264627']\n",
      "type_Submachine Gun = ['0.1243647749961698', '0.17764623469934337', '0.13968944674607467', '0.16489180975554957']\n",
      "type_Sniper Rifle = ['0.20409986011387757', '0.2807987844265283', '0.27995594897990034', '0.208446966822908']\n",
      "verdispersion = ['0.0903909175085929', '0.265368712287136', '0.2689630047677869', '0.11022535958685833']\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "random = tf.random_uniform(shape=[1,z_dim], minval=-100.0, maxval=100.0)\n",
    "noise_input = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
    "test_decoder = decoder_op(noise_input)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    generated = []\n",
    "    for i in range(4):\n",
    "        random_val = sess.run(random)\n",
    "        x_test = sess.run(test_decoder, feed_dict={noise_input: random_val})\n",
    "        generated.append(x_test[0])\n",
    "    print_decoded_tensors_as_dict(weapon_data, generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
