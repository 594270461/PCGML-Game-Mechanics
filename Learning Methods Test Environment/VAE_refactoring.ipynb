{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\z_outsourced_programs\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow version 1.8.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensor Flow version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on https://jmetzen.github.io/2015-11-27/vae.html\n",
    "\n",
    "class VariationalAutoencoder(object):\n",
    "    \"\"\" Variation Autoencoder (VAE) with an sklearn-like interface implemented using TensorFlow.\n",
    "    \n",
    "    This implementation uses probabilistic encoders and decoders using Gaussian \n",
    "    distributions and  realized by multi-layer perceptrons. The VAE can be learned\n",
    "    end-to-end.\n",
    "    \n",
    "    See \"Auto-Encoding Variational Bayes\" by Kingma and Welling for more details.\n",
    "    \n",
    "    @param: session TensorFlow session to execute the network. Provided with tf.Session() or tf.InteractiveSession\n",
    "    @param: network_architecture The network architecture for this VAE. The second hidden layer is optional!\n",
    "        E.g., network_architecture = dict(n_hidden_1=20, # 1st layer encoder/decoder neurons\n",
    "                                         n_hidden_2=20, # OPTIONAL: 2nd layer encoder/decoder neurons\n",
    "                                         n_input=50, # data input\n",
    "                                         n_z=10)  # dimensionality of latent space\n",
    "    @param: optimizer Optimizer used for training the network. Provided optimizer needs to implement .minimize() function!\n",
    "        E.g., optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    @param: transfer_fct Activation function after hidden layers.\n",
    "    @param: batch_size Batch size used in training.\n",
    "    @param: print_debug Prints debug messages of this class if set to True.\n",
    "    \"\"\"\n",
    "    def __init__(self, session, network_architecture, optimizer, transfer_fct=tf.nn.tanh, batch_size=1, print_debug=True):\n",
    "        self._print_debug = print_debug\n",
    "        self.__print_debug(\"Start initializing variational autoencoder (VAE) ...\")\n",
    "        \n",
    "        self._network_architecture = network_architecture\n",
    "        self._transfer_fct=transfer_fct\n",
    "        self._optimizer_provided = optimizer\n",
    "        self._batch_size = batch_size\n",
    "        self._has_2_hidden_layer = ('n_hidden_2' in network_architecture)\n",
    "        self.__print_debug(\"Does VAE have 2 hidden layers? \" + str(self._has_2_hidden_layer), 1)\n",
    "        \n",
    "        # Input\n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, network_architecture[\"n_input\"]]) \n",
    "        \n",
    "        # create the whole variational autoencoder network \n",
    "        self.__create_network()\n",
    "        \n",
    "        self.__create_loss_optimizer()\n",
    "        \n",
    "        #launch a tensorflow session\n",
    "        self._session = session\n",
    "        self._train_saver = tf.train.Saver()\n",
    "\n",
    "        #run the initializer for all tensorflow variables\n",
    "        self._session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        self.__print_debug(\"VAE ready to use!\")\n",
    "\n",
    "    def train_with_mini_batch(self, batch):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "        \n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        opt, cost = self._session.run((self.optimizer, self.cost), feed_dict={self.X: batch})\n",
    "        return cost\n",
    "    \n",
    "    def encode_to_latent_space(self, x):\n",
    "        \"\"\"Transform data by mapping it into the latent space.\"\"\"\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self._session.run(self.z_mean, feed_dict={self.X: x})\n",
    "    \n",
    "    def decode_from_latent_space(self, z):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self._session.run(self.x_reconstructed, feed_dict={self.x: z})\n",
    "    \n",
    "    def load_trained_model(self, save_path):\n",
    "        self._train_saver.restore(self._session, save_path)\n",
    "        \n",
    "    def save_trained_model(self, path):\n",
    "        save_path = self._train_saver.save(self._session, path + \"model.ckpt\") #Saves the weights (not the graph)\n",
    "        self.__print_debug(\"Model saved in file: {}\".format(save_path))\n",
    "        return save_path\n",
    "    \n",
    "    def __print_debug(self, message, indent=0):\n",
    "        if self._print_debug:\n",
    "            tabs=\"\"\n",
    "            for i in range(indent):\n",
    "                tabs += \"\\t\"\n",
    "            print(tabs+message)\n",
    "\n",
    "    def __create_network(self):\n",
    "        self.__print_debug(\"Start creating VAE network ...\", 1)\n",
    "        #init weights and biases of all network nodes\n",
    "        \n",
    "        weights_and_biases = self.__init_weights_and_biases()\n",
    "        \n",
    "        #create the encoder network which generates the latent network\n",
    "        self.z_mean, self.z_log_sigma_sq = \\\n",
    "            self.__create_encoder_network(weights_and_biases['weights_encoder'], \n",
    "                                          weights_and_biases['biases_encoder'])\n",
    "            \n",
    "        #create the sampling operation to:\n",
    "        # -) map our data distribution to a normal distribution \n",
    "        # -) and secure a working backpropagation\n",
    "        self.z = self.__create_z_sampling_operation()\n",
    "        \n",
    "        #create the decoder network which generates a reconstruction of input X\n",
    "        self.x_reconstructed = \\\n",
    "            self.__create_decoder_network(weights_and_biases['weights_decoder'], \n",
    "                                          weights_and_biases['biases_decoder'])\n",
    "        \n",
    "        self.__print_debug(\"Finished creating VAE network!\", 1)\n",
    "\n",
    "        \n",
    "    def __create_encoder_network(self, weights, biases):\n",
    "        self.__print_debug(\"Start creating encoder network ...\", 2)\n",
    "\n",
    "        hidden_layer = self.__create_hidden_layer(self.X, weights, biases)\n",
    "        \n",
    "        # Parameters for the Gaussian\n",
    "        z_mean = tf.matmul(hidden_layer, weights['z_mean']) + biases['z_mean']\n",
    "        z_log_sigma_sq = tf.matmul(hidden_layer, weights['z_ls2']) + biases['z_ls2']\n",
    "        \n",
    "        self.__print_debug(\"Finished creating encoder network!\", 2)\n",
    "        \n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "        \n",
    "    def __create_z_sampling_operation(self):\n",
    "        self.__print_debug(\"Start creating z (latent layer) sampling operation ...\", 2)\n",
    "        \n",
    "        n_z = self._network_architecture['n_z']\n",
    "        \n",
    "        # Adding a random number from the normal (gaussian) distribution\n",
    "        epsilon = tf.random_normal((self._batch_size, n_z), 0, 1, dtype=tf.float32) \n",
    "\n",
    "        # sample z from a normal (gaussian) distribution -> z = mu + sigma*epsilon\n",
    "        z = self.z_mean + tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), epsilon)\n",
    "        \n",
    "        self.__print_debug(\"Finished creating z sampling operation!\", 2)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def __create_decoder_network(self, weights, biases):\n",
    "        self.__print_debug(\"Start creating decoder/generator network ...\", 2)\n",
    "        \n",
    "        hidden_layer = self.__create_hidden_layer(self.z, weights, biases)\n",
    "        \n",
    "        x_reconstructed = tf.matmul(hidden_layer,  weights['out']) + biases['out']\n",
    "    \n",
    "        self.__print_debug(\"Finished creating decoder/generator network!\", 2)\n",
    "            \n",
    "        return x_reconstructed\n",
    "    \n",
    "    def __create_hidden_layer(self, x, weights, biases):\n",
    "        self.__print_debug(\"Start creating hidden layer ...\", 3)\n",
    "        \n",
    "        # First hidden layer\n",
    "        hidden_layer_1 = tf.matmul(x, weights['h1']) + biases['h1']\n",
    "        hidden_layer_1 = self._transfer_fct(hidden_layer_1)\n",
    "\n",
    "        # Second hidden layer\n",
    "        hidden_layer_2 = tf.matmul(hidden_layer_1, weights['h2']) + biases['h2']\n",
    "        hidden_layer_2 = self._transfer_fct(hidden_layer_2)\n",
    "\n",
    "        self.__print_debug(\"Finished creating hidden layer!\", 3)\n",
    "        \n",
    "        return hidden_layer_2 if self._has_2_hidden_layer else hidden_layer_1\n",
    "        \n",
    "    def __init_weights_and_biases(self):\n",
    "        self.__print_debug(\"Start initalizing weights and biases ...\", 2)\n",
    "\n",
    "        n_input = self._network_architecture['n_input']\n",
    "        n_hidden_1 = self._network_architecture['n_hidden_1']\n",
    "        n_hidden_2 = self._network_architecture['n_hidden_2'] if self._has_2_hidden_layer else 1\n",
    "        n_hidden_out = n_hidden_2 if self._has_2_hidden_layer else n_hidden_1\n",
    "        n_z = self._network_architecture['n_z']\n",
    "        \n",
    "        weights_and_biases = dict()\n",
    "        \n",
    "        #encoder\n",
    "        weights_and_biases['weights_encoder'] = {\n",
    "            'h1': self.__create_weight([n_input, n_hidden_1]),\n",
    "            'h2': self.__create_weight([n_hidden_1, n_hidden_2]),\n",
    "            'z_mean': self.__create_weight([n_hidden_out, n_z]),\n",
    "            'z_ls2': self.__create_weight([n_hidden_out, n_z])\n",
    "        }\n",
    "        weights_and_biases['biases_encoder'] = {\n",
    "            'h1': self.__create_bias([n_hidden_1]),\n",
    "            'h2': self.__create_bias([n_hidden_2]),\n",
    "            'z_mean': self.__create_bias([n_z]),\n",
    "            'z_ls2': self.__create_bias([n_z])\n",
    "        }\n",
    "        \n",
    "        #decoder\n",
    "        weights_and_biases['weights_decoder'] = {\n",
    "            'h1': self.__create_weight([n_z, n_hidden_1]),\n",
    "            'h2': self.__create_weight([n_hidden_1, n_hidden_2]),\n",
    "            'out': self.__create_weight([n_hidden_out, n_input])\n",
    "        }\n",
    "        weights_and_biases['biases_decoder'] = {\n",
    "            'h1': self.__create_bias([n_hidden_1]),\n",
    "            'h2': self.__create_bias([n_hidden_2]),\n",
    "            'out': self.__create_bias([n_input])\n",
    "        }\n",
    "        self.__print_debug(\"Finished initalizing weights and biases!\", 2)\n",
    "\n",
    "        return weights_and_biases\n",
    "    \n",
    "    def __create_loss_optimizer(self):\n",
    "        self.__print_debug(\"Start creating optimizer/backprop operation ...\", 1)\n",
    "\n",
    "        # The loss is composed of two terms:\n",
    "        #according to the VAE tutorial paper:\n",
    "        reconstr_loss = tf.reduce_sum(tf.square(tf.abs(self.X - self.x_reconstructed)), 1)\n",
    "        #reconstr_loss = self.__l2_loss(self.x_reconstructed, self.X)\n",
    "        #reconstr_loss = self.__cross_entropy(self.x_reconstructed, self.X)\n",
    "        \n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        latent_loss = self.__kullback_leibler(self.z_mean, tf.log(tf.sqrt(tf.exp(self.z_log_sigma_sq))))\n",
    "        \n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss)   # average over batch\n",
    "        self.optimizer = self._optimizer_provided.minimize(self.cost)\n",
    "\n",
    "        self.__print_debug(\"Finished creating optimizer/backprop operation!\", 1)\n",
    "\n",
    "            \n",
    "    def __create_weight(self, shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial, dtype=tf.float32)\n",
    "        #initial = tf.contrib.layers.xavier_initializer()\n",
    "        #return tf.Variable(initial(shape), dtype=tf.float32)\n",
    "\n",
    "    def __create_bias(self, shape):\n",
    "        initial = tf.constant(0.1, shape=shape, dtype=tf.float32)\n",
    "        return tf.Variable(initial, dtype=tf.float32)\n",
    "        #initial = tf.contrib.layers.xavier_initializer()\n",
    "        #return tf.Variable(initial(shape), dtype=tf.float32)\n",
    "        \n",
    "    def __kullback_leibler(self, mu, log_sigma):\n",
    "        \"\"\"(Gaussian) Kullback-Leibler divergence KL(q||p), per training example\"\"\"\n",
    "        # (tf.Tensor, tf.Tensor) -> tf.Tensor\n",
    "        with tf.name_scope(\"KL_divergence\"):\n",
    "            # = -0.5 * (1 + log(sigma**2) - mu**2 - sigma**2)\n",
    "            return -0.5 * tf.reduce_sum(1 + 2 * log_sigma - mu**2 - tf.exp(2 * log_sigma), 1)\n",
    "\n",
    "    def __cross_entropy(self, obs, actual, offset=1e-7):\n",
    "        \"\"\"Binary cross-entropy, per training example\"\"\"\n",
    "        # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "        with tf.name_scope(\"cross_entropy\"):\n",
    "            # bound by clipping to avoid nan (--> log(0))\n",
    "            obs_ = tf.clip_by_value(obs, offset, 1 - offset)\n",
    "            return -tf.reduce_sum(actual * tf.log(obs_) + (1 - actual) * tf.log(1 - obs_), 1)\n",
    "\n",
    "    def __l2_loss(self, obs, actual):\n",
    "        \"\"\"L2 loss (a.k.a. Euclidean / LSE), per training example\"\"\"\n",
    "        # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "        with tf.name_scope(\"l2_loss\"):\n",
    "            return tf.reduce_sum(tf.square(obs - actual), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weapon_data as weapons\n",
    "\n",
    "DEFAULT_MODEL_PATH = \"./trained_vae/\"\n",
    "weapon_data = weapons.DataSet(seed=19071991) \n",
    "num_samples = weapon_data.num_examples\n",
    "\n",
    "def train_vae(session, network_architecture, optimizer, transfer_fct,\n",
    "              batch_size=1, training_epochs=10, epoch_debug_step=5,\n",
    "              trained_model_save_path=DEFAULT_MODEL_PATH, \n",
    "              save_model = True, save_model_every_epoch = True):\n",
    "\n",
    "    #create vae\n",
    "    vae = VariationalAutoencoder(session=session, network_architecture=network_architecture, optimizer=optimizer, \n",
    "                                 transfer_fct=transfer_fct, batch_size=batch_size, print_debug=True)\n",
    "    trained_model_path = \"\"\n",
    "    #training cycle\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(num_samples / batch_size)\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch = weapon_data.next_batch(batch_size)\n",
    "            \n",
    "            # Fit training using batch data\n",
    "            cost = vae.train_with_mini_batch(batch)\n",
    "            \n",
    "            #compute average loss/cost\n",
    "            avg_cost += cost / num_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % epoch_debug_step == 0:\n",
    "            if save_model and save_model_every_epoch:\n",
    "                trained_model_path = vae.save_trained_model(trained_model_save_path)\n",
    "            print(\"Epoch:\"+ '%04d' % (epoch+1) + \", cost=\" + \"{:.9f}\".format(avg_cost))\n",
    "            \n",
    "    if save_model and not save_model_every_epoch:\n",
    "        trained_model_path = vae.save_trained_model(trained_model_save_path)\n",
    "    \n",
    "    if save_model:\n",
    "        print(\"Trained model saved! You can find it in '\"+trained_model_path+\"'\")\n",
    "        \n",
    "        \n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start initializing variational autoencoder (VAE) ...\n",
      "\tDoes VAE have 2 hidden layers? True\n",
      "\tStart creating VAE network ...\n",
      "\t\tStart initalizing weights and biases ...\n",
      "\t\tFinished initalizing weights and biases!\n",
      "\t\tStart creating encoder network ...\n",
      "\t\t\tStart creating hidden layer ...\n",
      "\t\t\tFinished creating hidden layer!\n",
      "\t\tFinished creating encoder network!\n",
      "\t\tStart creating z (latent layer) sampling operation ...\n",
      "\t\tFinished creating z sampling operation!\n",
      "\t\tStart creating decoder/generator network ...\n",
      "\t\t\tStart creating hidden layer ...\n",
      "\t\t\tFinished creating hidden layer!\n",
      "\t\tFinished creating decoder/generator network!\n",
      "\tFinished creating VAE network!\n",
      "\tStart creating optimizer/backprop operation ...\n",
      "\tFinished creating optimizer/backprop operation!\n",
      "VAE ready to use!\n",
      "Model saved in file: ./trained_vae/model.ckpt\n",
      "Epoch:0001, cost=23.166244739\n",
      "Model saved in file: ./trained_vae/model.ckpt\n",
      "Epoch:0002, cost=23.116669397\n",
      "Model saved in file: ./trained_vae/model.ckpt\n",
      "Epoch:0003, cost=20.970647335\n",
      "Model saved in file: ./trained_vae/model.ckpt\n",
      "Epoch:0004, cost=18.806916765\n",
      "Model saved in file: ./trained_vae/model.ckpt\n",
      "Epoch:0005, cost=18.841982339\n",
      "Model saved in file: ./trained_vae/model.ckpt\n",
      "Epoch:0006, cost=17.980345520\n",
      "Model saved in file: ./trained_vae/model.ckpt\n",
      "Epoch:0007, cost=18.170760387\n",
      "Model saved in file: ./trained_vae/model.ckpt\n",
      "Epoch:0008, cost=16.686542550\n",
      "Model saved in file: ./trained_vae/model.ckpt\n",
      "Epoch:0009, cost=15.303349559\n",
      "Model saved in file: ./trained_vae/model.ckpt\n",
      "Epoch:0010, cost=15.934579759\n",
      "Trained model saved! You can find it in './trained_vae/model.ckpt'\n"
     ]
    }
   ],
   "source": [
    "network_architecture = \\\n",
    "    dict(n_input=weapon_data.num_features,\n",
    "         n_hidden_1=14,\n",
    "         n_hidden_2=15,\n",
    "         n_z=2)  \n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer =  tf.train.AdamOptimizer(learning_rate)\n",
    "#optimizer = tf.train.RMSPropOptimizer(learning_rate)\n",
    "transfer_fct = lambda x : tf.nn.tanh(x)\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "epoch_debug_step = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    vae = train_vae(sess, network_architecture, optimizer, transfer_fct, batch_size, num_epochs, epoch_debug_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
