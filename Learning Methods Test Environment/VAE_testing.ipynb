{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\z_outsourced_programs\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow version 1.8.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensor Flow version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on https://jmetzen.github.io/2015-11-27/vae.html\n",
    "\n",
    "class VariationalAutoencoder(object):\n",
    "    \"\"\" Variation Autoencoder (VAE) with an sklearn-like interface implemented using TensorFlow.\n",
    "    \n",
    "    This implementation uses probabilistic encoders and decoders using Gaussian \n",
    "    distributions and  realized by multi-layer perceptrons. The VAE can be learned\n",
    "    end-to-end.\n",
    "    \n",
    "    See \"Auto-Encoding Variational Bayes\" by Kingma and Welling for more details.\n",
    "    \n",
    "    @param: session TensorFlow session to execute the network. Provided with tf.Session() or tf.InteractiveSession\n",
    "    @param: network_architecture The network architecture for this VAE. The second hidden layer is optional!\n",
    "        E.g., network_architecture = dict(n_hidden_1=20, # 1st layer encoder/decoder neurons\n",
    "                                         n_hidden_2=20, # OPTIONAL: 2nd layer encoder/decoder neurons\n",
    "                                         n_input=50, # data input\n",
    "                                         n_z=10)  # dimensionality of latent space\n",
    "    @param: optimizer Optimizer used for training the network. Provided optimizer needs to implement .minimize() function!\n",
    "        E.g., optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    @param: transfer_fct Activation function after hidden layers.\n",
    "    @param: batch_size Batch size used in training.\n",
    "    @param: print_debug Prints debug messages of this class if set to True.\n",
    "    \"\"\"\n",
    "    def __init__(self, session, network_architecture, optimizer, transfer_fct=tf.nn.tanh, batch_size=1, print_debug=True):\n",
    "        self._print_debug = print_debug\n",
    "        self.__print_debug(\"Start initializing variational autoencoder (VAE) ...\")\n",
    "        \n",
    "        self._network_architecture = network_architecture\n",
    "        self._transfer_fct=transfer_fct\n",
    "        self._optimizer_provided = optimizer\n",
    "        self._batch_size = batch_size\n",
    "        self._has_2_hidden_layer = ('n_hidden_2' in network_architecture)\n",
    "        self.__print_debug(\"Does VAE have 2 hidden layers? \" + str(self._has_2_hidden_layer), 1)\n",
    "        \n",
    "        # Input\n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, network_architecture[\"n_input\"]], name=\"input_X\") \n",
    "        \n",
    "        # create the whole variational autoencoder network \n",
    "        self.__create_network()\n",
    "        \n",
    "        self.__create_loss_optimizer()\n",
    "        \n",
    "        #launch a tensorflow session\n",
    "        self._session = session\n",
    "        self._train_saver = tf.train.Saver()\n",
    "\n",
    "        #run the initializer for all tensorflow variables\n",
    "        self._session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        self.__print_debug(\"VAE ready to use!\")\n",
    "\n",
    "    def train_with_mini_batch(self, batch):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "        \n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        opt, cost = self._session.run((self.optimizer, self.cost), feed_dict={self.X: batch})\n",
    "        return cost\n",
    "    \n",
    "    def encode_to_latent_space(self, x):\n",
    "        \"\"\"Transform data by mapping it into the latent space.\"\"\"\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self._session.run(self.z_mean, feed_dict={self.X: x})\n",
    "    \n",
    "    def decode_from_latent_space(self, z):\n",
    "        \"\"\" Generate data by sampling from latent space. \"\"\"\n",
    "        return self._session.run(self.x_reconstructed, feed_dict={self.z: z})\n",
    "    \n",
    "    def encode_and_decode(self, x):\n",
    "        \"\"\" Use VAE to reconstruct given data. Encodes and decodes in the same run.\"\"\"\n",
    "        return self._session.run(self.x_reconstructed, feed_dict={self.X: x})\n",
    "    \n",
    "    def load_trained_model(self, save_path):\n",
    "        ''' Loads trained model from disk. CAUTION: need to open session with 'tf.Session(graph=tf.Graph())'!'''\n",
    "        self._train_saver.restore(self._session, save_path)\n",
    "        self.__print_debug(\"Trained model found in '\"+save_path+\"' restored!\")\n",
    "        \n",
    "    def save_trained_model(self, path):\n",
    "        save_path = self._train_saver.save(self._session, path + \"model.ckpt\") #Saves the weights (not the graph)\n",
    "        self.__print_debug(\"Model saved in file: {}\".format(save_path))\n",
    "        return save_path\n",
    "    \n",
    "    \n",
    "    def calculate_z(self, X):\n",
    "        return self._session.run(self.z, feed_dict={self.X: X})\n",
    "    \n",
    "    def calculate_z_mean(self, X):\n",
    "        return self._session.run(self.z_mean, feed_dict={self.X: X})\n",
    "        \n",
    "    def __print_debug(self, message, indent=0):\n",
    "        if self._print_debug:\n",
    "            tabs=\"\"\n",
    "            for i in range(indent):\n",
    "                tabs += \"\\t\"\n",
    "            print(tabs+message)\n",
    "\n",
    "    def __create_network(self):\n",
    "        self.__print_debug(\"Start creating VAE network ...\", 1)\n",
    "        #init weights and biases of all network nodes\n",
    "        \n",
    "        weights_and_biases = self.__init_weights_and_biases()\n",
    "        \n",
    "        #create the encoder network which generates the latent network\n",
    "        self.z_mean, self.z_log_sigma_sq = \\\n",
    "            self.__create_encoder_network(weights_and_biases['weights_encoder'], \n",
    "                                          weights_and_biases['biases_encoder'])\n",
    "            \n",
    "        #create the sampling operation to:\n",
    "        # -) map our data distribution to a normal distribution \n",
    "        # -) and secure a working backpropagation\n",
    "        self.z = self.__create_z_sampling_operation()\n",
    "        \n",
    "        #create the decoder network which generates a reconstruction of input X\n",
    "        self.x_reconstructed = \\\n",
    "            self.__create_decoder_network(weights_and_biases['weights_decoder'], \n",
    "                                          weights_and_biases['biases_decoder'])\n",
    "        \n",
    "        self.__print_debug(\"Finished creating VAE network!\", 1)\n",
    "\n",
    "        \n",
    "    def __create_encoder_network(self, weights, biases):\n",
    "        self.__print_debug(\"Start creating encoder network ...\", 2)\n",
    "\n",
    "        hidden_layer = self.__create_hidden_layer(self.X, weights, biases)\n",
    "        \n",
    "        # Parameters for the Gaussian\n",
    "        z_mean = tf.matmul(hidden_layer, weights['z_mean']) + biases['z_mean']\n",
    "        z_log_sigma_sq = tf.matmul(hidden_layer, weights['z_ls2']) + biases['z_ls2']\n",
    "        \n",
    "        self.__print_debug(\"Finished creating encoder network!\", 2)\n",
    "        \n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "        \n",
    "    def __create_z_sampling_operation(self):\n",
    "        self.__print_debug(\"Start creating z (latent layer) sampling operation ...\", 2)\n",
    "        \n",
    "        n_z = self._network_architecture['n_z']\n",
    "        \n",
    "        # Adding a random number from the normal (gaussian) distribution\n",
    "        epsilon = tf.random_normal((self._batch_size, n_z), 0, 1, dtype=tf.float32) \n",
    "\n",
    "        # sample z from a normal (gaussian) distribution -> z = mu + sigma*epsilon\n",
    "        z = self.z_mean + tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), epsilon)\n",
    "        \n",
    "        self.__print_debug(\"Finished creating z sampling operation!\", 2)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def __create_decoder_network(self, weights, biases):\n",
    "        self.__print_debug(\"Start creating decoder/generator network ...\", 2)\n",
    "        \n",
    "        hidden_layer = self.__create_hidden_layer(self.z, weights, biases)\n",
    "        \n",
    "        x_reconstructed = tf.matmul(hidden_layer,  weights['out']) + biases['out']\n",
    "    \n",
    "        self.__print_debug(\"Finished creating decoder/generator network!\", 2)\n",
    "            \n",
    "        return x_reconstructed\n",
    "    \n",
    "    def __create_hidden_layer(self, x, weights, biases):\n",
    "        self.__print_debug(\"Start creating hidden layer ...\", 3)\n",
    "        \n",
    "        # First hidden layer\n",
    "        hidden_layer_1 = tf.matmul(x, weights['h1']) + biases['h1']\n",
    "        hidden_layer_1 = self._transfer_fct(hidden_layer_1)\n",
    "\n",
    "        # Second hidden layer\n",
    "        hidden_layer_2 = tf.matmul(hidden_layer_1, weights['h2']) + biases['h2']\n",
    "        hidden_layer_2 = self._transfer_fct(hidden_layer_2)\n",
    "\n",
    "        self.__print_debug(\"Finished creating hidden layer!\", 3)\n",
    "        \n",
    "        return hidden_layer_2 if self._has_2_hidden_layer else hidden_layer_1\n",
    "        \n",
    "    def __init_weights_and_biases(self):\n",
    "        self.__print_debug(\"Start initalizing weights and biases ...\", 2)\n",
    "\n",
    "        n_input = self._network_architecture['n_input']\n",
    "        n_hidden_1 = self._network_architecture['n_hidden_1']\n",
    "        n_hidden_2 = self._network_architecture['n_hidden_2'] if self._has_2_hidden_layer else 1\n",
    "        n_hidden_out = n_hidden_2 if self._has_2_hidden_layer else n_hidden_1\n",
    "        n_z = self._network_architecture['n_z']\n",
    "        \n",
    "        weights_and_biases = dict()\n",
    "        \n",
    "        #encoder\n",
    "        weights_and_biases['weights_encoder'] = {\n",
    "            'h1': self.__create_weight([n_input, n_hidden_1], \"w_enc_h1\"),\n",
    "            'h2': self.__create_weight([n_hidden_1, n_hidden_2], \"w_enc_h2\"),\n",
    "            'z_mean': self.__create_weight([n_hidden_out, n_z], \"w_z_mean\"),\n",
    "            'z_ls2': self.__create_weight([n_hidden_out, n_z], \"w_z_ls2\")\n",
    "        }\n",
    "        weights_and_biases['biases_encoder'] = {\n",
    "            'h1': self.__create_bias([n_hidden_1], \"b_enc_h1\"),\n",
    "            'h2': self.__create_bias([n_hidden_2], \"b_enc_h2\"),\n",
    "            'z_mean': self.__create_bias([n_z], \"b_z_mean\"),\n",
    "            'z_ls2': self.__create_bias([n_z], \"b_z_ls2\")\n",
    "        }\n",
    "        \n",
    "        #decoder\n",
    "        weights_and_biases['weights_decoder'] = {\n",
    "            'h1': self.__create_weight([n_z, n_hidden_1], \"w_dec_h1\"),\n",
    "            'h2': self.__create_weight([n_hidden_1, n_hidden_2], \"w_dec_h2\"),\n",
    "            'out': self.__create_weight([n_hidden_out, n_input], \"w_out\")\n",
    "        }\n",
    "        weights_and_biases['biases_decoder'] = {\n",
    "            'h1': self.__create_bias([n_hidden_1], \"b_dec_h1\"),\n",
    "            'h2': self.__create_bias([n_hidden_2], \"b_dec_h2\"),\n",
    "            'out': self.__create_bias([n_input], \"b_out\")\n",
    "        }\n",
    "        self.__print_debug(\"Finished initalizing weights and biases!\", 2)\n",
    "\n",
    "        return weights_and_biases\n",
    "    \n",
    "    def __create_loss_optimizer(self):\n",
    "        self.__print_debug(\"Start creating optimizer/backprop operation ...\", 1)\n",
    "\n",
    "        # The loss is composed of two terms:\n",
    "        #according to the VAE tutorial paper:\n",
    "        reconstr_loss = tf.reduce_sum(tf.square(tf.abs(self.X - self.x_reconstructed)), 1)\n",
    "        #reconstr_loss = self.__l2_loss(self.x_reconstructed, self.X)\n",
    "        #reconstr_loss = self.__cross_entropy(self.x_reconstructed, self.X)\n",
    "        \n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        latent_loss = self.__kullback_leibler(self.z_mean, tf.log(tf.sqrt(tf.exp(self.z_log_sigma_sq))))\n",
    "        \n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss)   # average over batch\n",
    "        self.optimizer = self._optimizer_provided.minimize(self.cost)\n",
    "\n",
    "        self.__print_debug(\"Finished creating optimizer/backprop operation!\", 1)\n",
    "\n",
    "            \n",
    "    def __create_weight(self, shape, name=\"\"):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial, dtype=tf.float32, name=name)\n",
    "        #initial = tf.contrib.layers.xavier_initializer()\n",
    "        #return tf.Variable(initial(shape), dtype=tf.float32, name=name)\n",
    "\n",
    "    def __create_bias(self, shape, name=\"\"):\n",
    "        initial = tf.constant(0.1, shape=shape, dtype=tf.float32)\n",
    "        return tf.Variable(initial, name=name)\n",
    "        #return tf.Variable(tf.zeros(shape, dtype=tf.float32), name=name)\n",
    "        #initial = tf.contrib.layers.xavier_initializer()\n",
    "        #return tf.Variable(initial(shape), dtype=tf.float32, name=name)\n",
    "        \n",
    "    def __kullback_leibler(self, mu, log_sigma):\n",
    "        \"\"\"(Gaussian) Kullback-Leibler divergence KL(q||p), per training example\"\"\"\n",
    "        # (tf.Tensor, tf.Tensor) -> tf.Tensor\n",
    "        with tf.name_scope(\"KL_divergence\"):\n",
    "            # = -0.5 * (1 + log(sigma**2) - mu**2 - sigma**2)\n",
    "            return -0.5 * tf.reduce_sum(1 + 2 * log_sigma - mu**2 - tf.exp(2 * log_sigma), 1)\n",
    "\n",
    "    def __cross_entropy(self, obs, actual, offset=1e-7):\n",
    "        \"\"\"Binary cross-entropy, per training example\"\"\"\n",
    "        # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "        with tf.name_scope(\"cross_entropy\"):\n",
    "            # bound by clipping to avoid nan (--> log(0))\n",
    "            obs_ = tf.clip_by_value(obs, offset, 1 - offset)\n",
    "            return -tf.reduce_sum(actual * tf.log(obs_) + (1 - actual) * tf.log(1 - obs_), 1)\n",
    "\n",
    "    def __l2_loss(self, obs, actual):\n",
    "        \"\"\"L2 loss (a.k.a. Euclidean / LSE), per training example\"\"\"\n",
    "        # (tf.Tensor, tf.Tensor, float) -> tf.Tensor\n",
    "        with tf.name_scope(\"l2_loss\"):\n",
    "            return tf.reduce_sum(tf.square(obs - actual), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL_PATH = \"./trained_vae/\"\n",
    "\n",
    "def train_vae(vae, weapon_data, batch_size=1, training_epochs=10, epoch_debug_step=5,\n",
    "              trained_model_save_path=DEFAULT_MODEL_PATH, \n",
    "              save_model = True, save_model_every_epoch = True):\n",
    "    \n",
    "    num_samples = weapon_data.num_examples\n",
    "    trained_model_path = \"\"\n",
    "    \n",
    "    #training cycle\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(num_samples / batch_size)\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch = weapon_data.next_batch(batch_size)\n",
    "            \n",
    "            # Fit training using batch data\n",
    "            cost = vae.train_with_mini_batch(batch)\n",
    "            \n",
    "            #compute average loss/cost\n",
    "            avg_cost += cost / num_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % epoch_debug_step == 0:\n",
    "            if save_model and save_model_every_epoch:\n",
    "                trained_model_path = vae.save_trained_model(trained_model_save_path)\n",
    "            print(\"Epoch:\"+ '%04d' % (epoch+1) + \", cost=\" + \"{:.9f}\".format(avg_cost))\n",
    "            \n",
    "    if save_model and not save_model_every_epoch:\n",
    "        trained_model_path = vae.save_trained_model(trained_model_save_path)\n",
    "    \n",
    "    if save_model:\n",
    "        print(\"Trained model saved! You can find it in '\"+trained_model_path+\"'\")\n",
    "\n",
    "#just a convenience wrapper\n",
    "def get_untrained_vae(session, network_architecture, optimizer, transfer_fct, batch_size=1):\n",
    "    \n",
    "    return VariationalAutoencoder(session=session, network_architecture=network_architecture, optimizer=optimizer, \n",
    "                                 transfer_fct=transfer_fct, batch_size=batch_size, print_debug=False)\n",
    "\n",
    "#just a convenience wrapper\n",
    "def get_new_trained_vae(session, weapon_data, network_architecture, optimizer, transfer_fct,\n",
    "                          batch_size=1, training_epochs=10, epoch_debug_step=5,\n",
    "                          trained_model_save_path=DEFAULT_MODEL_PATH, \n",
    "                          save_model = True, save_model_every_epoch = True):\n",
    "\n",
    "    #create vae\n",
    "    vae = get_untrained_vae(session=session, network_architecture=network_architecture, optimizer=optimizer, \n",
    "                                 transfer_fct=transfer_fct, batch_size=batch_size)\n",
    "    \n",
    "    #train it\n",
    "    vae = train_vae(vae, weapon_data, batch_size, training_epochs, epoch_debug_step, \n",
    "                       trained_model_save_path, save_model, save_model_every_epoch)\n",
    "        \n",
    "    return vae\n",
    "\n",
    "#just a convenience wrapper\n",
    "def restore_vae(untrained_vae, model_path):\n",
    "    untrained_vae.load_trained_model(model_path)\n",
    "    return untrained_vae\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test utils\n",
    "\n",
    "def print_decoded_tensors_as_dict(weapon_data, array_of_tensors):\n",
    "    genDict = {}\n",
    "    \n",
    "    for tensor in array_of_tensors:\n",
    "        decoded = weapon_data.decode_processed_tensor(tensor)\n",
    "        \n",
    "        for key, value in decoded.items():\n",
    "            if key not in genDict:\n",
    "                genDict[key] = []\n",
    "            genDict[key].append(value)\n",
    "    \n",
    "    for key, value in genDict.items():\n",
    "            print(key, \"=\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001, cost=24.254438684\n",
      "Epoch:0002, cost=21.861828524\n",
      "Epoch:0003, cost=19.749310435\n",
      "Epoch:0004, cost=17.830332134\n",
      "Epoch:0005, cost=17.137048847\n",
      "Epoch:0006, cost=14.804081640\n",
      "Epoch:0007, cost=14.060663368\n",
      "Epoch:0008, cost=14.799999667\n",
      "Epoch:0009, cost=12.446837770\n",
      "Epoch:0010, cost=13.160067779\n",
      "Trained model saved! You can find it in './trained_vae/model.ckpt'\n"
     ]
    }
   ],
   "source": [
    "import weapon_data as weapons\n",
    "\n",
    "network_architecture = \\\n",
    "    dict(n_input=0, #set it in with scope\n",
    "         n_hidden_1=14,\n",
    "         n_hidden_2=15,\n",
    "         n_z=2)  \n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer =  tf.train.AdamOptimizer(learning_rate)\n",
    "#optimizer = tf.train.RMSPropOptimizer(learning_rate)\n",
    "transfer_fct = lambda x : tf.nn.tanh(x)\n",
    "num_epochs = 10\n",
    "batch_size = 1\n",
    "epoch_debug_step = 1\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    weapon_data = weapons.DataSet(seed=19071991) \n",
    "    network_architecture['n_input'] = weapon_data.num_features\n",
    "  \n",
    "    vae = get_new_trained_vae(sess, weapon_data, network_architecture, optimizer, \n",
    "                              transfer_fct, batch_size, num_epochs, epoch_debug_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_vae/model.ckpt\n",
      "[[-0.70326645 -0.48674743 -0.30162464 -0.29826301 -0.22336265  1.3003496\n",
      "  -0.75793673 -0.59816232  0.19378264 -1.11913753 -0.86609068 -0.28002455\n",
      "   0.55030494  2.19514536  3.58362519  0.55859823 -0.28577464 -0.32322997\n",
      "  -0.50421948 -0.54611868 -0.36023741 -0.52522573  2.45919073 -0.2672411 ]]\n",
      "[[-0.8756247  -0.51307255 -0.46652347 -0.48351285 -0.09164627  1.3460879\n",
      "  -0.7955996  -0.56146747  1.2990477  -0.57705593 -0.8507605  -0.13715252\n",
      "   0.11545181  0.55893874  0.3069438   1.3266746  -0.1432753  -0.40696168\n",
      "  -0.4218165  -0.40320772  0.9521485  -0.32813042  0.88883924 -0.20152833]]\n",
      "damages_first = ['26.5', '22.233594628702704']\n",
      "damages_last = ['20.0', '19.368608812548743']\n",
      "dmg_distances_first = ['11.0', '8.549149101995123']\n",
      "dmg_distances_last = ['50.0', '42.274955501132496']\n",
      "drag = ['0.0024999999441206455', '0.002659377651834734']\n",
      "firemode_Automatic = ['1.0', '1.0221025000409791']\n",
      "firemode_Semi-Automatic = ['0.0', '-0.01813060439110481']\n",
      "hiprecoildec = ['6.0', '9.01490972054171']\n",
      "hiprecoilright = ['0.15000000596046448', '0.3634422127275845']\n",
      "hiprecoilup = ['0.20000000298023224', '0.24309985427327385']\n",
      "hordispersion = ['0.0', '0.07446348689902335']\n",
      "initialspeed = ['700.0', '608.9023005981226']\n",
      "magsize = ['120.0', '50.3779397772508']\n",
      "reloadempty = ['8.75979995727539', '4.2918889104878994']\n",
      "rof = ['450.0', '620.2314136238381']\n",
      "shotspershell = ['1.0', '1.4110430008510244']\n",
      "type_Shotgun = ['-1.3877787807814457e-17', '-0.024504433791955535']\n",
      "type_Pistol = ['2.7755575615628914e-17', '0.03312705777912181']\n",
      "type_Rifle = ['2.7755575615628914e-17', '0.06011678008693047']\n",
      "type_Submachine Gun = ['0.0', '0.4184657821401508']\n",
      "type_Sniper Rifle = ['0.0', '0.08113692656823768']\n",
      "verdispersion = ['0.0', '0.03131817531497348']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    vae = get_untrained_vae(sess, network_architecture, optimizer, transfer_fct, batch_size)\n",
    "    vae = restore_vae(vae, \"trained_vae/model.ckpt\")\n",
    "        \n",
    "    weapon_data = weapons.DataSet(seed=19071991) \n",
    "    samples = weapon_data.next_batch(batch_size)\n",
    "    x_reconstructed = vae.encode_and_decode(samples)\n",
    "    \n",
    "    print(samples)\n",
    "    print(x_reconstructed)\n",
    "    \n",
    "    print_decoded_tensors_as_dict(weapon_data, np.concatenate((samples,x_reconstructed), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_vae/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1eb49876668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1EAAAEzCAYAAADQJonSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3X+UXGWd5/HPJ00LDXJokICkTQyjbMQhmqx9CJ6cs+svDKIDbZSRjDg4o5NxzzAjjptjIhwBB5fMZkdndvSMRmXRhYlxNLQZkzWg4GF1TSSYYBNDRlQmSXcOASSoQ6udznf/qKpMJanqrtt9695bVe/XOfd03aduPfW93aGabz/P830cEQIAAAAANGZG3gEAAAAAQCshiQIAAACABEiiAAAAACABkigAAAAASIAkCgAAAAASIIkCAAAAgASmnUTZPsX2920/bHuX7VvSCAwAAAAAisjT3SfKtiWdFhG/st0t6TuS3h8RW9MIEAAAAACK5KTpdhClLOxX5dPu8sEOvgAAAADaUipromx32d4p6aCkeyNiWxr9AgAAAEDRTHskSpIiYlzSAtu9ku62fVFEPFJ9je3lkpZL0mmnnfaql73sZWm8NQCgwB566KGnImJm3nG0CvvUkHrzDgMogDNrN/f11G7/de3mnrn/VvcdRh+qN5bwTP2wMIkDqX3mv9SO55K+u7QlIi5L4/0nk0oSVRERh2x/W9Jlkh457rm1ktZKUn9/f2zfvj3NtwYAFJDtf807htbSq/LfG4EOt7R285+/onb7o7Wb/8P/qr9E/2GfWueZDfXDwiRuSe0z/zlJf5rwNTdLZ6f1/pNJozrfzPIIlGz3SHqD6v5TBgAAAICJWaXRniRHltJ4v/MkfcF2l0pJ2Zcj4usp9AsAAACgA1mlanVFlUZ1vh9KWphCLAAAAABwdCSqqIocGwAAADrS/NrNK29O1MvDd0zlvW+q037LVDrDFLX9SBQAAAAApImRKAAAAABIgJEoAAAAAEiAkSgAAAAASICRKAAAAABIgJEoAAAAIJG0KuFdOMFzu5v83pgORqIAAAAAIAGSKAAAAABIqMiJSpFjAwAAANCBGIkCAAAAgASKXlhiRt4BAAAAAEC1ykhUkmPSPu3Ztu+3vdv2LtvvL7ffbHvY9s7ycflkfRU5wQMAAADQgZo0EnVY0gcj4ge2T5f0kO17y899IiL+R6MdkUQBAAAAaHsRcUDSgfLjX9reLalvKn0xnQ8AAABAoTRjOt8x/dtzJS2UtK3cdJ3tH9q+3faZk72eJAoAgCko/6I9aPuROs+/xvazVXPsP5J1jADQqirT+ZIcks62vb3qWF6zb/v5kr4q6fqI+IWkf5D0EkkLVBqp+pvJ4mM6HwAAU3OHpE9K+uIE1/zfiHhLNuEAQPuYYonzpyKif8J+7W6VEqi7ImKDJEXEE1XPf1bS1yd7I5IoAACmICIeKE8HAZCZpXXadydsR9E1o7CEbUv6vKTdEfHxqvbzyuulJOmtkmrOMKhGEgUAQPO82vbDkkYk/deI2JV3QADQCpq02e5iSe+SNGR7Z7ntw5KW2V4gKSQ9LulPJ+uIJAoAgOb4gaQXR8SvynuODEq64PiLynP2y/P2z8gyPgAorGYkURHxnXLXx9uctC8KSwAA0AQR8YuI+FX58WZJ3bbPrnHd2ojoL83jPzXzOAGgqKZQWCLT2AAAQMpsv1DSExERti9W6Q+XT+ccFgC0BEvqTpqpHG5GJLWRRAEAMAW210l6jUoldfdLuknl2ScR8WlJb5f0X2wfljQq6eqIiJzCBdrEhrwDQEZs6SSSKAAA2ktELJvk+U+qVAIdAJCQLXV35R1FfSRRAAAAAAplSiNRGSpwaAAAAAA60ZTWRGWowKEBAAAA6EiWxHQ+AAAAAGiQVehMpcChAQAAAOhIJFEAAAAAkFCBM5UZeQcAAAAAAK2kwPkdAAAAgI5EYQkAAAAASIA1UQAAAACQAEkUAAAAACTEdD4AAAAAaFDBR6KmXZ3P9mzb99vebXuX7fenERgAAACADlVJopIcGUrj7Q5L+mBE/MD26ZIesn1vRPwohb4BAAAAdKJ2ns4XEQckHSg//qXt3ZL6JJFEAQAAAEiu4NP5Ug3N9lxJCyVtS7NfAAAAoD1cWKd9d6ZRFF6nJFG2ny/pq5Kuj4hf1Hh+uaTlkjRnzpy03hYAAABAuyl4EjXtwhKSZLtbpQTqrojYUOuaiFgbEf0R0T9z5sw03hYAAABAu+pKeGRo2vmdbUv6vKTdEfHx6YcEAAAAoKN1wEjUYknvkvQ62zvLx+Up9AsAAACgE7V7ifOI+I5KtwkAAAC0qbQKQlBAoiFWe5c4BwAAAIBUFXw6X4FDA/I3uGNYa7bs0cihUc3q7dGKJfM0sLAv77AAAADaX4EzlQKHBuRncMewbt64S4dGx462DR8a1fXrd2rFP+1Ud9cMPTd2pOZrT+2eof+29BUkWwAAAG0qlRLnQDsZ3DGsFf/08DEJVLWxI6qbQEml565fv1MXfHiTBncMNytMAACA9lVZE1XQEuckUcBxbt64S2NHYtr9jB2Rrl+/Uws/eg/JFAAALW93nQNN0e7V+YB2U28EaqqeeW5Mf/nlnbp+/c6jbYtfcpbu+pNXp/o+AAAAbaPghSUYiQKqvPOz32tKv8cPbH33Jz9v2nsBAAC0BUaigNbw3Z/8vC3fCwAAoKWwTxQAAAAAJMB0PqB99XR3afFLzpLzDgQAAKCdFLywBEkUUGXxS86q2/746jfrb9+xQH29PbKkvt4e3bZ0vh5/elS1avl12bKkk0+q/Z9ZvfcC0Bps3277oO1H6jxv2//T9mO2f2j7P2YdIwC0tAKXOC/wIBmQvbv+5NV652e/d8x6pepKegML+07YRPcDVVX3qh2J0M9Wv1mSJuwTQMu6Q9InJX2xzvNvknRB+Vgk6R/KXwEAkyn4dL4ChwbkI2lyM6u3R8OHRmu2T7VPAMUXEQ/YnjvBJVdK+mJEhKSttnttnxcRBzIJEABaWcGTKKbzAdP02pfNTNQOoGP0SdpXdb6/3AYAmEzB10QVOL8DWsP9jz6ZqB1Ax6hVc+aEJZS2l0taXjo7o7kRAUArocQ50JpuHBzSum37NB6hLlvLFs3WrQPzj7lmpMZUvonaAXSM/ZJmV52/SNLI8RdFxFpJayXJnlWrTg0A5OSmOu23NP+tCz6dr8ChAfm6cXBId27de/R8PEJ3bt2rnz35Kz3+9KhGDo1qVm+Pek/t1jPPjZ3w+uo1UQA60kZJ19n+kkoFJZ5lPRQANIgkCmhN67btq9leXWVv+NCoumdY3V3W2Pi//wG5p7tLK5bMa3qMAPJje52k10g62/Z+lf5k2y1JEfFpSZslXS7pMUnPSfqjfCIFgBaV8nQ+27NVqqj6QklHJK2NiL+zfZak9ZLmSnpc0u9HxDMT9UUSBdQxHo3Nqhk7Eurt6dZpJ590dHRqxZJ5J5RCB9BeImLZJM+HpD/LKBwAaC/NGYk6LOmDEfED26dLesj2vZLeLelbEbHa9kpJKyV9aKKOSKKAOrrshhOpZ0fHtPOmNzY5IgAAAExVeUr1gfLjX9rerVLV1CtVmlkgSV+Q9G1NkkRR4hyoY9mi2ZNfVMb6JwAAgBRNrcT52ba3Vx3L63Zf2udvoaRtks6trFktfz1nsvAYiQLqqFThq67Od8nvnKkf7H1Wo2PjR69j/RMAAGhPGVThq8eaypqopyKif9Ku7edL+qqk6yPiF3atHSkmRhIFTODWgfknlDQf3DGsNVv2sP4JAACgWZpUnc92t0oJ1F0RsaHc/ITt8yLigO3zJB2crB+SKCChgYV9JE0AAADNlnKm4tKQ0+cl7Y6Ij1c9tVHStZJWl79+LePQAAAAAGCamjMStVjSuyQN2d5ZbvuwSsnTl22/R9JeSVdN1hFJFAAAAIBimdqaqAlFxHfKPdfy+iR9kUQBAAAAHe3COu27M43iGE1aE5WWAocGAAAAoGMVOFMpcGhAZ6MKIAAA6FhNmM6XJpIooIAGdwxr1Yaho/tRDR8a1aoNQ5JEIgUAANpfwafzzcg7AAAnWrNlzzEb+krS6Ni41mzZk1NEAAAAGaokUUmODBU4vwPaS5LpeSOHRhO1AwAAtB2m8wGdLen0vFm9PRqukTDN6u1pbqAAAKAD5ViFrx6m8wFIOj1vxZJ56uk+9s8vPd1dWrFkXtNiBAAAKAym8wFIOj2vMjpFdT4AANCRCj4SVeDQgPYxlel5Awv7SJoAAEDnKvCaKKbzARlgeh4AAEACBZ/Ol0oSZft22wdtP5JGf0C7GVjYp9uWzldfb48sqa+3R7ctnc9IEwAAQAtKK2e7Q9InJX0xpf6AtsP0PAAAgAZ1wpqoiHjA9tw0+gIAAACAIq+JKnB+ByBrNw4O6R+37dWRKJ33dM/QbUtfwQgaAADIVieMRDXC9nJJyyVpzpw5Wb0tgAbdODikO7fuPaZtdOyI/nL9Tkm1NwUGAABoioInUZlV54uItRHRHxH9M2fOzOptATRo3bZ9NduPSHU3BQYAAGiKglfnK3B+ByBL4xF1n6u3KTAAAECzRIHXRKVV4nydpO9Jmmd7v+33pNEvgOx02XWfm2hTYAAAgLSFpfGTkh1ZSqs637I0+gGQn2WLZp+wJkoq/aWFTYEBAECmnH1ilESBQwOQlcEdw7r/0SdPaKc6HwAAyENYOtyVdNLckabEUgtJFNDhBncMa9WGIY2OjR9t6+nu0m1L55M8AQCAXISt8ZOSpiq/bUostWRWnQ9AMa3ZsueYBEqSRsfGqcgHAAByNd7VlejIEkkU0OHqVd6jIh8wMduX2d5j+zHbK2s8/27bT9reWT7em0ecANCKQta4uhIdWWI6H9DhZvX2aLhGwkRFPqA+212SPiXpUkn7JT1oe2NE/Oi4S9dHxHWZBwgALS5kHc44MUqCkSigw61YMk893cd+SPV0d1GRD5jYxZIei4ifRsRvJX1J0pU5xwQAbWVcJyU6ssRIFNDhKsUj1mzZo5FDo5rV26MVS+ZRVAKYWJ+kfVXn+yUtqnHd22z/J0n/IukDEbGvxjUAgONUpvMVFUkUAA0s7CNpApKptTt1HHf+z5LWRcRvbL9P0hckve6EjuzlkpaXzs5IN0oAE7iwTvvuTKMotvy+R0VPopjOBwBAcvslza46f5GkkeoLIuLpiPhN+fSzkl5Vq6OIWBsR/RHRL53alGABAOliJAoAgOQelHSB7fMlDUu6WtIfVF9g+7yIOFA+vUL8eRsAEinySBRJFAAACUXEYdvXSdoiqUvS7RGxy/ZHJW2PiI2S/sL2FZIOS/q5pHfnFjAAtJiiV+cjiQIAYAoiYrOkzce1faTq8SpJq7KOCwDaQWlNVHFTleJGBgAAAKBjMZ0PAAAAKBSWKU4uv+9R0avzkUQBOGpwxzD7RQEAgNyFxJooAMU3uGNYqzYMaXRsXJI0fGhUqzYMSRKJFAAAyFix10SxTxQASdKaLXuOJlAVo2PjWrNlT04RAQCATlWZzpfkyFJx0zugBbXydLiRQ6OJ2gEAAJqJNVFAB2j16XCzens0XCNhmtXbk0M0AAAgO0vrtG/INIpqRS8swXQ+ICWtPh1uxZJ56uk+9sOqp7tLK5bMyykiAADQqSqb7SY5ssRIFJCSVp8OVxkta9XpiAAAoL0UubBEcSMDWkwrToe7cXBI67bt03iEumwtWzRb3135urzDAgAAHa5Z0/ls3y7pLZIORsRF5babJf2JpCfLl304IjZP1A/T+YCUtNp0uBsHh3Tn1r0aj5AkjUfozq17dePgUM6RAQCATtfE6nx3SLqsRvsnImJB+ZgwgZJIooDUDCzs021L56uvt0eW1Nfbo9uWzi/sdLh12/YlagcAAMhSM9ZERcQDkn4+3diYzgekaGBhX2GTpuNVRqAabQcAAO2qThW+s2+u3f5UnfYURfab7V5n+w8lbZf0wYh4ZqKLGYkCOlSXXfe5wR3DGUYCAACQirNtb686ljf4un+Q9BJJCyQdkPQ3k72AJAroUMsWza773PXrd7I2CgAA5GaKa6Keioj+qmNtQ+8V8UREjEfEEUmflXTxZK8hiQI61K0D83XNJXPqPn/n1r2MSAEAgNw0qbDECWyfV3X6VkmPTPYakiigg906MH/C51tlo2AAANBemrXZru11kr4naZ7t/bbfI+m/2x6y/UNJr5X0gcn6obAEgLpaZaNgAADQBBkUkKinWYUlImJZjebPJ+2HJArocJZUrx5fkTcKBgAA7a0Zm+2mhel8QId7Z511UTOswm4UDAAA2lsTN9tNBSNRQIcZ3DGsNVv2aOTQqGb19hxNlO7atlfVW0QdiVKVvps37tLNV/xuy+x/BQAAWl8liSoqRqKADjK4Y1irNgxp+NCoQtLwoVGt2jCk/hefpZ/d9mb97TsWaMZx20cdGh3T9et3au7KTZq7cpMu/fi38wgdAAB0mGYUlkgLSRTQQdZs2aPRsfFj2kbHxo9W4bt54y4dqbdAquzHB/9Nc1dualaIAAAARwtLJDmyxHQ+oIPUq7Y3cmhUgzuGdWh0rOG+5q7cpMdXvzmt0AAAQNNdWKd9d532pQn7vyXh9fUVfTpfKkmU7csk/Z2kLkmfi4jVafQLYPqq10DNsDUeJw419XTP0AfW78whOgAAgNraOomy3SXpU5IulbRf0oO2N0bEj6bbN9AOahVyyKpIQ2UNVGUKX60ESpKeGzuSSTwAAACNqGy2W1RpjERdLOmxiPipJNn+kqQrJZFEoeMdn8RUCjlIyiSRqrUGSpp4bygAAIC8NWuz3bSkUViiT9K+qvP95Tag401WyKHZ6q2BIoECAABF1+77RLlG2wn/j2Z7uaTlkjRnTu3NPYF2M1EhhyzM6u3R8DTe68xTu/XMc7WLTXS51n/6AAAgX/WKR0j1C0jUfs0Zvz6nZvv1p5xXsz29shLFLyyRxkjUfkmzq85fJGnk+IsiYm1E9EdE/8yZM1N4W6D4ZvX2JGpPanDHsBavvk/nr9ykxavv0+CO4WOeX7Fknnq6k38AWdI1l8zRjo+8UddcUvuPHssWza7ZDgAAkIYij0SlkUQ9KOkC2+fbfp6kqyVtTKFfoOXVSmJ6uru0Ysm8afddb+Pc6kRqYGGfbls6P1G/XbY+8Y4FunWg9LpbB+brmkvmHB156rJ1zSVzjj4PAADQaaY9nS8iDtu+TtIWlUqc3x4Ru6YdGdAGKsUjmlGdb6L1VtX9Dyzs05otexqa1tfT3aXbls4/Ib5bB+aTNAHHmWx7D9snS/qipFdJelrSOyLi8azjBIBW1AnV+RQRmyVtTqMvoN0MLOxrSiW+JOutViyZd0yVQKmUML3tVX26/9Encym/DrSyBrf3eI+kZyLipbavlvTXkt6RfbQA0HqKXp2vuJEBmFC9ohG11ls1c0QM6FCNbO9xpaSby4+/IumTth1RZ8M2AAVRrzBDvaIMRTOVOGvf87OnfLpm+y26qU4/aZaWaPPNdgHko97oUr31Vs0aEQM6VK3tPRbVu6Y89f1ZSS+Q9FQmEQJAC+uE6nwAclApGtHX2yNL6u3p1indM/SB9TtrVuoDkKpGtvdoeAsQ29ttb5eeSyU4AGh1lTVRSY4skUQBLWxgYZ++u/J1+sQ7Fug3h4/omefG6lbqA5CqRrb3OHqN7ZMknSHp58d3VL0FiHRqk8IFgNYzrpMSHVkiiQLawESV+gA0RSPbe2yUdG358dsl3cd6KABoTGU6X1H3iWJNFNAGklTqAzB99bb3sP1RSdsjYqOkz0v637YfU2kE6ur8IgaA1lL0NVEkUUAbSFKpD0A6am3vEREfqXr8a0lXZR0XgOkqWhW+NKsF1utrwxT6ar4iJ1FM5wPawIol89TTfewHzUSV+gAAAIqs6IUlGIkC2gD7QAEAgHbCZrsAMsE+UAAAoJ0UeTofSRQAAACAQqGwBAAAAIApSrPQRdGKZtRXWRNVVCRRAAAAAAqHNVEAAAAA0KCiT+ejxDkAAAAAJMBIFAAAAIBCKfpIFEkUAAAAgMKhsAQAAACAFF1Yp711KvBNhM12AQAAACABpvMBAAAAQEIkUQAAAADQIEaiAAAAACCBEIUlAAAAAKSqPQpI1EdhCQAAAABoGNP5AAAAACAhkqgWtOhj9+qJX/72mDZLeuclc3TrwPx8ggIAAAA6QMiFXhM1I+8AiqhWAiWVFrjduXWvbhwcyj4oAAAAoENUNttNcjTC9u22D9p+pKrtLNv32v5x+euZk/VDElVDrQSq2rpt+yRJNw4O6SWrNmvuyk16yarNJFeYssEdw1q8+j6dv3KTFq++T4M7hvMOCQAAIFfj6kp0NOgOSZcd17ZS0rci4gJJ3yqfT4jpfFMwHqEbB4d059a9x7RVzpnuhyQGdwxr1YYhjY6NS5KGD41q1YZSQj6wsC/P0AAAAHLRrMISEfGA7bnHNV8p6TXlx1+Q9G1JH5qoH0aipqDLPjoadbx67UA9a7bsOZpAVYyOjWvNlj05RQQAAJCvkDV+pCvRMQ3nRsQBSSp/PWeyF5BE1XDu6c+b8Plli2ZrPKLmc/XagXpGDo0magcAAGh7IR0+3JXokHS27e1Vx/JmhUcSVcO2Gy6tmUhZ0jXl6nxdds3X1msH6pnV25OoHQAAoN1FWOOHT0p0SHoqIvqrjrUNvt0Tts+TpPLXg5O9gDVRdWy74dIJn1+2aPYxa6Kq24EkViyZd8yaKEnq6e7SiiXzcowKAACgY2yUdK2k1eWvX5vsBSRRU1QpHrFu2z6NR6jL1rJFsykqgcQqxSPWbNmjkUOjmtXboxVL5lFUAgAAdKzSSFT6hSVsr1OpiMTZtvdLukml5OnLtt8jaa+kqybrhyRqGm4dmE/ShFQMLOwjaQIAAKgINSWJiohldZ56fZJ+SKIAAAAAFEqEdXgs/SQqLdMqLGH7Ktu7bB+x3Z9WUAAAAAA6mXVk/KRER5am+26PSFoq6TMpxAIAAAAAUkhqwnS+tEwriYqI3ZJkynoDADqE7bMkrZc0V9Ljkn4/Ip6pcd24pKHy6d6IuCKrGAGg5YULnUSxTxQAAMmslPStiLhA0rfK57WMRsSC8kECBQBJhKTDTnZkaNKRKNvflPTCGk/dEBGT1lCv6me5pOWSNGfOnIYDBACgYK5UqTyuJH1B0rclfSivYACgbR3OO4D6Jk2iIuINabxRecfgtZLU398fafQJAEAOzo2IA5IUEQdsn1PnulNsb1fpfwNWR8RgZhECQKsLtXYSBQBAp5loFkaCbuZExIjt35F0n+2hiPhJjfc6OlNDOmMK0QJAG2rnJMr2WyX9vaSZkjbZ3hkRS1KJDACAnEw0C8P2E7bPK49CnSfpYJ0+Rspff2r725IWSjohiaqeqWHPYqYGAEilJGos7yDqm1ZhiYi4OyJeFBEnR8S5JFAAgA6wUdK15cfXSjphfbDtM22fXH58tqTFkn6UWYQA0OpC0njCI0NU5wMAIJnVki61/WNJl5bPZbvf9ufK11woabvthyXdr9KaKJIoAEjicMIjQ6yJAgAggYh4WtLra7Rvl/Te8uP/J2l+xqEBQPto5zVRAAAAAJA6kigAAAAASIAkCkC1wR3DWrNlj0YOjWpWb49WLJmngYV9eYcFAACABpFEARka3DGsVRuGNDpWKiEzfGhUqzYMSRKJFAAAQEXBR6KozgdkaM2WPUcTqIrRsXGt2bInp4gAAAAKiup8ACRp5NBoonYAAICO1M6b7QJIZlZvT8323lO7M44EAACgwNhsF+hMgzuGtXj1fTp/5SYtXn2fBncMa8WSeeru8gnX/urXhzW4YziHKAEAAAqosiaK6XxA56hXQOK2pfN12vNO0qHRY8enx46E1mzZQ3EJoOPNknRTjfZbsg4EAPJV8MISJFFAE0xUQOLZ0doTfFkXBQAAUFbwJIrpfEATTFRAot66qBn2MVP/AAAAOlqBp/ORRAFNUC9Rqmyu29PddcJz4xEKlab+rfjKwyRSAACgcxV8TRRJFNAEtRKlnu4urVgyTwML+3Tb0vnq6+2RJfnEOhMaGw/d8s+7sgkWAACgaAqeRLEmCmiCSoGINVv2HJ3CV0mgKs9XHs9dualmH888V+DNEQA0xwsk/V6Nv6zcUe8FS+u0b0glHACNuLBO++5Mo2g7Bd8niiQKaJLqRGmqbhwc0q0D81OKCAAAoEVU9okqKJIoIGe9Pd0nlDyvuHPrXt25da8s6Wer35xtYAAAAHmiOh+Aem6+4nfVPaPG9J0qofrT/gAAANpOwddEkUQBORtY2Kc1V72yoWvnrtykd372e02OCAAAIGckUQAmM7CwT121yvTV8N2f/FyLPnZvkyMCAADIUaWwRJIjQ6yJAgpi2aLZunPr3oaufeKXv6XoBNCOnh6R7rg5wQuowgfkjyp8nYiRKKAgbh2Yr1O6GhuNkqR12/Y1MRoAAIAcVarzJTkyRBIFFMijH7u84URqPKLJ0QAAAOSINVEAGvXoxy7XNZfMmfS6RtdQAQAAtBwKSwBI6taB+Xp89ZsnTKaWLZqdYUQAAAAZKnhhCZIooMBuHZivv33HAvV0//t/qjMsXXPJHIpKAACA9lXwNVFU5wMKbmBhnwYW9uUdBgAAQHYq0/kKiiQKAAAAQPGQRAEAAABAgyprogqKJAoAAABAsVTWRBUUSRQAAACAYmFNFAAAAAAk0KQkyvbjkn6p0jjX4Yjon0o/lDgHACAB21fZ3mX7iO26v3xtX2Z7j+3HbK/MMkYAaHnN3SfqtRGxYKoJlEQSBQBAUo9IWirpgXoX2O6S9ClJb5L0cknLbL88m/AAoE2wTxQAAO0hInZLku2JLrtY0mMR8dPytV+SdKWkHzU9QABoB1Obzne27e1V52sjYm2Nnu+xHZI+U+P5hpBEAQCQvj5J+6rO90talFMsANB6ppZEPdXAFL3FETFi+xxJ99p+NCLqziyoZ1pJlO01kn5P0m8l/UTSH0XEoen0CQBA3mx/U9ILazx1Q0R8rZEuarRFnfdaLml56eyMBiMEgDbXpH2iImKk/PWg7btVmjmQOIma7pqoeyVdFBGvkPQWEqvwAAALP0lEQVQvklZNsz8AAHIXEW+IiItqHI0kUFJp5Gl21fmLJI3Uea+1EdFf+uvpqdMNHQBQh+3TbJ9eeSzpjSqtc01sWiNREXFP1elWSW+fTn8AALSJByVdYPt8ScOSrpb0B/mGBAAtpDmb7Z4r6e7ymtaTJP1jRHxjKh2luSbqjyWtr/dk9XSFOXPmpPi2AABkx/ZbJf29pJmSNtneGRFLbM+S9LmIuDwiDtu+TtIWSV2Sbo+IXTmGDQCtJ+V9osrFfl6ZRl+TJlGNzAu3fYNKt3lXvX7KlS/WSlJ/f3/NeeEAABRdRNwt6e4a7SOSLq863yxpc4ahAUD7aNJmu2mZNImKiDdM9LztayW9RdLrI4LkCAAAAMD0NKmwRFqmW53vMkkfkvSfI+K5dEICAAAA0NGasyYqNdNdE/VJSSerVGNdkrZGxPumHRUAAACAztXq0/kmEhEvTSsQAAAAADiqXZMoAAAAAEhdO6+JAgAAAIDUtfmaKAAAAABIVzuviQIAAACA1JFEAQAAAEACrIkCAAAAgIRYEwUAAAAACUTeAdRHEgUAAABM6sI67bszjQLFMCPvAAAAAACglZBEAQAAAEACJFEAAAAAkABrogAAAAAUTLFrnJNEAQAAACiYYu+2SxIFAAAATIoqfNliJAoAAAAAEmAkCgAAAAASYCQKAAAAABIgiQIAAACAhJjOBwAAALSACxNeT8GJ5mAkCgAAAAASoLAEAAAAACTASBQAAAAAJMBIFAAAAAAkwEgUAAAAACTASBQAAADQIpJW21tap33DdAPpcIxEAQAAAEACjEQBAAAAQALFHomakXcAAAC0EttX2d5l+4jt/gmue9z2kO2dtrdnGSMAoLkYiQIAIJlHVFoE8ZkGrn1tRDzV5HgAoE0xnQ8AgLYQEbslyXbeoQAohNoFJN4Sv1uz/eve1cxg2kixp/ORRAEA0Bwh6R7bIekzEbG21kW2l0taXjo7I7PgAKDYSKIAAGgptr8p6YU1nrohIr7WYDeLI2LE9jmS7rX9aEQ8cPxF5eRqbel9Z8WUgwaAtkJ1PgAAWkpEvCGFPkbKXw/avlvSxZJOSKIAALUUeySK6nwAAKTM9mm2T688lvRGlQpSAAAaUhmJSnJkhyQKAIAEbL/V9n5Jr5a0yfaWcvss25vLl50r6Tu2H5b0fUmbIuIb+UQMAK2oMhKV5MgO0/kAAEggIu6WdHeN9hFJl5cf/1TSKzMODUCBfP2PrqrZ/sqYXbP9YfN3lmMVe03UtEaibP+V7R+WNxK8x/astAIDAAAA0KmaMxJl+zLbe2w/ZnvlVKOb7nS+NRHxiohYIOnrkj4yzf4AAAAAdLz010TZ7pL0KUlvkvRySctsv3wq0U1rOl9E/KLq9DSV7hYAAAAApqEp1fkulvRYecq1bH9J0pWSfpS0o2mvibL9MUl/KOlZSa+dbn8AAAAAOl1T1kT1SdpXdb5f0qKpdOSIiQePGt1w0PYqSadExE11+qnakV0XqXNLvZ4t6am8g8hRJ99/J9+71Nn338n3Pi8iTs87iFZh+0lJ/5pjCO3wb7Ud7kFqj/vgHoohy3t4cUTMTKMj299QKfYkTpH066rzteUNzSt9XiVpSUS8t3z+LkkXR8SfJ45vsiSq4Y7sF6tUwvWiBq7dHhH9qbxxi+nke5c6+/47+d6lzr5/7r0z770VtcPPqx3uQWqP++AeiqEd7iEttl8t6eaIWFI+XyVJEXFb0r6mW53vgqrTKyQ9Op3+AAAAAKBJHpR0ge3zbT9P0tWSNk6lo+muiVpte56kIypNP3jfNPsDAAAAgNRFxGHb10naIqlL0u0RsWsqfU23Ot/bpvjStZNf0rY6+d6lzr7/Tr53qbPvn3tHq2iHn1c73IPUHvfBPRRDO9xDaiJis6TN0+0ntTVRAAAAANAJprvZLgAAAAB0lNySKNt/ZfuHtnfavsf2rLxiyZrtNbYfLd//3bZ7844pS7avsr3L9hHbHVEtxvZltvfYfsz2yrzjyZLt220ftN1x2xrYnm37ftu7y//m3593TFmxfYrt79t+uHzvt+QdE07U6O+jIn+GNfo7xfbjtofK/9+xPcsYG5HgPor8szjL9r22f1z+emad68bLP4edtqe0qD9tk31fbZ9se335+W2252Yf5cQauId3236y6nv/3jzibBd5jkStiYhXRMQCSV+X9JEcY8navZIuiohXSPoXSatyjidrj0haKumBvAPJgu0uSZ+S9CZJL5e0zPbL840qU3dIuizvIHJyWNIHI+JCSZdI+rMO+tn/RtLrIuKVkhZIusz2JTnHhBNN+vuoBT7DkvxOeW1ELChouedJ76MFfhYrJX0rIi6Q9K3yeS2j5Z/Dgoi4Irvwamvw+/oeSc9ExEslfULSX2cb5cQS/NtYX/W9/1ymQbaZ3JKoiPhF1elpKm1L3BEi4p6IqGzBvFXSi/KMJ2sRsTsi9uQdR4YulvRYRPw0In4r6UuSrsw5psxExAOSfp53HHmIiAMR8YPy419K2q3SbultL0p+VT7tLh8d8znfKhr8fVToz7B2+Z3S4H0U+mehUixfKD/+gqSBHGNJopHva/W9fUXS6207wxgnU/R/G20n1zVRtj9me5+kd6qzRqKq/bGk/5N3EGiqPkn7qs73q0P+Rxr/rjz1Y6GkbflGkh3bXbZ3Sjoo6d6I6Jh7b1H1fh+1y2dYSLrH9kO2l+cdzBQV/WdxbkQckEp/RJJ0Tp3rTrG93fZW20VItBr5vh69pvyHh2clvSCT6BrT6L+Nt5Wn737F9uxsQmtP090nakK2vynphTWeuiEivhYRN0i6obxb8HWSbmpmPFma7N7L19yg0nSfu7KMLQuN3H8HqfWXKv4i30FsP1/SVyVdf9wofFuLiHFJC8rrbO62fVFEdNzauLyl8Pso98+wlH6nLI6IEdvnSLrX9qPlkfLMpHAfhf5ZJOhmTvln8TuS7rM9FBE/SSfCKWnk+5r7934SjcT3z5LWRcRvbL9PpZG11zU9sjbV1CQqIt7Q4KX/KGmT2iiJmuzebV8r6S2SXh9tWGc+wc++E+yXVP3XnhdJGskpFmTMdrdKCdRdEbEh73jyEBGHbH9bpbVxJFEZS+H3Ue6fYWn8TomIkfLXg7bvVmn6U6ZJVAr3Ueifhe0nbJ8XEQdsn6fSKHStPio/i5+WPxsWSsoziWrk+1q5Zr/tkySdoWJNVZ/0HiLi6arTz6pg67paTZ7V+S6oOr1C0qN5xZI125dJ+pCkKyLiubzjQdM9KOkC2+fbfp6kqyUVohoRmqs8X/7zknZHxMfzjidLtmdWKr3Z7pH0BnXQ53yraPD3Uct/htk+zfbplceS3qjWTOiL/rPYKOna8uNrJZ0wumb7TNsnlx+fLWmxpB9lFmFtjXxfq+/t7ZLuK9gfwSe9h3JiW3GFSut0MUV5rolabfsR2z9U6cOsY0r/SvqkpNNVmk6w0/an8w4oS7bfanu/pFdL2mR7S94xNVN57vR1krao9IH15YjYlW9U2bG9TtL3JM2zvd/2e/KOKUOLJb1L0uuqSspenndQGTlP0v3lz/gHVVoT9fWcY8KJav4+sj3L9map+J9h9X6nVN+DpHMlfcf2w5K+L2lTRHwjn4hra+Q+iv6zkLRa0qW2fyzp0vK5bPfbrlSCu1DS9vLP4n5JqyMi1ySq3vfV9kdtV6oHfl7SC2w/JukvVb/yYC4avIe/cKmM/sOS/kLSu/OJtj24WEk0AAAAABRbrtX5AAAAAKDVkEQBAAAAQAIkUQAAAACQAEkUAAAAACRAEgUAAAAACZBEAQAAAEACJFEAAAAAkABJFAAAAAAk8P8BkpefllD5/6EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eb4891f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "all_z = np.zeros((1,network_architecture['n_z']))\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    vae = get_untrained_vae(sess, network_architecture, optimizer, transfer_fct, batch_size)\n",
    "    vae = restore_vae(vae, \"trained_vae/model.ckpt\")\n",
    "    \n",
    "    weapon_data = weapons.DataSet(seed=19071991) \n",
    "    total_batch = int(weapon_data.num_examples / batch_size) \n",
    "    \n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch = weapon_data.next_batch(batch_size)\n",
    "        z_mean = vae.calculate_z_mean(batch)\n",
    "        all_z = np.vstack((all_z, z_mean))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(all_z[:,0], all_z[:,1])\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist2d(all_z[:,0], all_z[:,1], (50, 50), cmap=plt.cm.jet)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained_vae/model.ckpt\n",
      "damages_first = ['90.9313774012717', '37.43811763273066', '33.10123002171909', '24.6148019660377']\n",
      "damages_last = ['68.5089369609525', '17.624477976991365', '19.16248637763192', '18.613666667179494']\n",
      "dmg_distances_first = ['7.519778608077821', '20.913327302867074', '17.55593384716672', '10.87909001393608']\n",
      "dmg_distances_last = ['119.3850092349387', '40.28082392105604', '42.12210882891269', '41.13229526474803']\n",
      "drag = ['0.0022201657393044662', '0.002905896959056628', '0.0025450090387301853', '0.0027096591777627083']\n",
      "firemode_Automatic = ['-0.029967369225196716', '0.12300466088913897', '0.42850111170699984', '0.8675256979105361']\n",
      "firemode_Semi-Automatic = ['0.06538128149936795', '0.8510658647349805', '0.5904633220979767', '0.15572371607021407']\n",
      "hiprecoildec = ['3.8497985207646543', '4.818307415206965', '6.267057114297727', '8.272315281484177']\n",
      "hiprecoilright = ['1.044191286303061', '0.5824521250367651', '0.4694656390614766', '0.39466020822823655']\n",
      "hiprecoilup = ['6.2656730041078035', '2.732915585421671', '1.529717625277735', '0.6584433934985912']\n",
      "hordispersion = ['-0.04130746503905253', '0.2034271171704093', '0.05371434809945637', '0.10060454563802079']\n",
      "initialspeed = ['675.4922113791159', '441.1483630283352', '504.45736433485126', '574.5254544637872']\n",
      "magsize = ['11.727894979242784', '5.774559048102134', '19.847626288051284', '42.179463564053606']\n",
      "reloadempty = ['4.1860084493458976', '3.1953460834567986', '3.470426750185528', '4.082512398084268']\n",
      "rof = ['67.16968469952485', '329.02979606937737', '437.60550136836616', '573.2118816153295']\n",
      "shotspershell = ['0.668950853170234', '2.0244813983375813', '1.1324995977682142', '1.5294851589449578']\n",
      "type_Shotgun = ['0.11338684201895423', '0.12894467202717524', '0.01625305974307402', '0.0033415205122835218']\n",
      "type_Pistol = ['0.11938874257747037', '0.5595360274587945', '0.423849182258883', '0.13573527675850555']\n",
      "type_Rifle = ['-0.04206084171996141', '0.39203089945610337', '0.32073424415749874', '0.12739903585780127']\n",
      "type_Submachine Gun = ['-0.028311436457940473', '0.005045815181513522', '0.14155048087314542', '0.3466217418995273']\n",
      "type_Sniper Rifle = ['0.850213383299691', '-0.03564535376779887', '0.0032258259100831632', '0.044145653082393405']\n",
      "verdispersion = ['-0.03320082773544272', '0.1309475055218791', '-0.0029100903433212644', '0.048503542477089004']\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    vae = get_untrained_vae(sess, network_architecture, optimizer, transfer_fct, batch_size)\n",
    "    vae = restore_vae(vae, \"trained_vae/model.ckpt\")\n",
    "    \n",
    "    generated = []\n",
    "    for i in range(4):\n",
    "        random_val = np.random.normal(size=(1,network_architecture[\"n_z\"]))\n",
    "        x_test = vae.decode_from_latent_space(random_val)\n",
    "        generated.append(x_test[0])\n",
    "        \n",
    "    weapon_data = weapons.DataSet(seed=19071991) \n",
    "    print_decoded_tensors_as_dict(weapon_data, generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
